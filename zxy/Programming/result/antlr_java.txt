{"ProxyErrorListener":{}}
{"ObjectEqualityComparator":{"hashCode":"\/** \n * {@inheritDoc}<p>This implementation returns {@code obj.}{@link Object#hashCode hashCode()}.<\/p>\n *\/\n","equals":"\/** \n * {@inheritDoc}<p>This implementation relies on object equality. If both objects are {@code null}, this method returns  {@code true}. Otherwise if only {@code a} is {@code null}, this method returns  {@code false}. Otherwise, this method returns the result of {@code a.}{@link Object#equals equals}{@code (b)}.<\/p>\n *\/\n"}}
{"TestRig":{}}
{"EqualityComparator":{"hashCode":"\/** \n * This method returns a hash code for the specified object.\n * @param obj The object.\n * @return The hash code for {@code obj}.\n *\/\n","equals":"\/** \n * This method tests if two objects are equal.\n * @param a The first object to compare.\n * @param b The second object to compare.\n * @return {@code true} if {@code a} equals {@code b}, otherwise  {@code false}.\n *\/\n"}}
{"Pair":{}}
{"Interval":{"startsAfter":"\/** \n * Does this.a start after other.b? May or may not be disjoint \n *\/\n","disjoint":"\/** \n * Are both ranges disjoint? I.e., no overlap? \n *\/\n","of":"\/** \n * Interval objects are used readonly so share all with the same single value a==b up to some max size.  Use an array as a perfect hash. Return shared object for 0..INTERVAL_POOL_MAX_VALUE or a new Interval object with a..a in it.  On Java.g4, 218623 IntervalSets have a..a (set with 1 element).\n *\/\n","intersection":"\/** \n * Return the interval in common between this and o \n *\/\n","length":"\/** \n * return number of elements between a and b inclusively. x..x is length 1. if b &lt; a, then length is 0.  9..10 has length 2.\n *\/\n","startsBeforeDisjoint":"\/** \n * Does this start completely before other? Disjoint \n *\/\n","adjacent":"\/** \n * Are two intervals adjacent such as 0..41 and 42..42? \n *\/\n","union":"\/** \n * Return the interval computed from combining this and other \n *\/\n","startsAfterNonDisjoint":"\/** \n * Does this start after other? NonDisjoint \n *\/\n","differenceNotProperlyContained":"\/** \n * Return the interval with elements from this not in other; other must not be totally enclosed (properly contained) within this, which would result in two disjoint intervals instead of the single one returned by this method.\n *\/\n","startsBeforeNonDisjoint":"\/** \n * Does this start at or before other? Nondisjoint \n *\/\n","startsAfterDisjoint":"\/** \n * Does this start completely after other? Disjoint \n *\/\n"}}
{"IntSet":{"add":"\/** \n * Adds the specified value to the current set.\n * @param el the value to add\n * @exception IllegalStateException if the current set is read-only\n *\/\n","or":"\/** \n * Return a new  {@link IntSet} object containing all elements that arepresent in the current set, the specified set  {@code a}, or both. <p> This method is similar to  {@link #addAll(IntSet)}, but returns a new {@link IntSet} instance instead of modifying the current set.<\/p>\n * @param a The set to union with the current set. A {@code null} argumentis treated as though it were an empty set.\n * @return A new {@link IntSet} instance containing the union of the currentset and  {@code a}. The value  {@code null} may be returned in place of anempty result set.\n *\/\n","subtract":"\/** \n * Return a new  {@link IntSet} object containing all elements that arepresent in the current set but not present in the input set  {@code a}. The following expressions are equivalent for input non-null {@link IntSet} instances {@code x} and {@code y}. <ul> <li> {@code y.subtract(x)}<\/li> <li> {@code x.complement(y)}<\/li> <\/ul>\n * @param a The set to compare with the current set. A {@code null}argument is treated as though it were an empty set.\n * @return A new {@link IntSet} instance containing the elements present in{@code elements} but not present in the current set. The value{@code null} may be returned in place of an empty result set.\n *\/\n","toList":"\/** \n * Return a list containing the elements represented by the current set. The list is returned in ascending numerical order.\n * @return A list containing all element present in the current set, sortedin ascending numerical order.\n *\/\n","remove":"\/** \n * Removes the specified value from the current set. If the current set does not contain the element, no changes are made.\n * @param el the value to remove\n * @exception IllegalStateException if the current set is read-only\n *\/\n","contains":"\/** \n * Returns  {@code true} if the set contains the specified element.\n * @param el The element to check for.\n * @return {@code true} if the set contains {@code el}; otherwise  {@code false}.\n *\/\n","size":"\/** \n * Return the total number of elements represented by the current set.\n * @return the total number of elements represented by the current set,regardless of the manner in which the elements are stored.\n *\/\n","addAll":"\/** \n * Modify the current  {@link IntSet} object to contain all elements that arepresent in itself, the specified  {@code set}, or both.\n * @param set The set to add to the current set. A {@code null} argument istreated as though it were an empty set.\n * @return {@code this} (to support chained calls)\n * @exception IllegalStateException if the current set is read-only\n *\/\n","and":"\/** \n * Return a new  {@link IntSet} object containing all elements that arepresent in both the current set and the specified set  {@code a}.\n * @param a The set to intersect with the current set. A {@code null}argument is treated as though it were an empty set.\n * @return A new {@link IntSet} instance containing the intersection of thecurrent set and  {@code a}. The value  {@code null} may be returned inplace of an empty result set.\n *\/\n","equals":"\/** \n * {@inheritDoc}\n *\/\n","isNil":"\/** \n * Returns  {@code true} if this set contains no elements.\n * @return {@code true} if the current set contains no elements; otherwise,{@code false}.\n *\/\n","toString":"\/** \n * {@inheritDoc}\n *\/\n","complement":"\/** \n * Return a new  {@link IntSet} object containing all elements that arepresent in  {@code elements} but not present in the current set. Thefollowing expressions are equivalent for input non-null  {@link IntSet}instances  {@code x} and {@code y}. <ul> <li> {@code x.complement(y)}<\/li> <li> {@code y.subtract(x)}<\/li> <\/ul>\n * @param elements The set to compare with the current set. A {@code null}argument is treated as though it were an empty set.\n * @return A new {@link IntSet} instance containing the elements present in{@code elements} but not present in the current set. The value{@code null} may be returned in place of an empty result set.\n *\/\n"}}
{"Array2DHashSet":{"asElementType":"\/** \n * Return  {@code o} as an instance of the element type {@code T}. If {@code o} is non-null but known to not be an instance of {@code T}, this method returns  {@code null}. The base implementation does not perform any type checks; override this method to provide strong type checks for the {@link #contains} and {@link #remove} methods to ensure the arguments tothe  {@link EqualityComparator} for the set always have the expectedtypes.\n * @param o the object to try and cast to the element type of the set\n * @return {@code o} if it could be an instance of {@code T}, otherwise {@code null}.\n *\/\n","getOrAdd":"\/** \n * Add  {@code o} to set if not there; return existing value if alreadythere. This method performs the same operation as  {@link #add} aside fromthe return value.\n *\/\n","createBucket":"\/** \n * Return an array of  {@code T} with length {@code capacity}.\n * @param capacity the length of the array to return\n * @return the newly constructed array\n *\/\n","createBuckets":"\/** \n * Return an array of  {@code T[]} with length {@code capacity}.\n * @param capacity the length of the array to return\n * @return the newly constructed array\n *\/\n"}}
{"LogManager":{}}
{"Utils":{"sequence":"\/** \n * @since 4.6 \n *\/\n","expandTabs":"\/** \n * @since 4.6 \n *\/\n","newlines":"\/** \n * @since 4.6 \n *\/\n","toMap":"\/** \n * Convert array of strings to string&rarr;index map. Useful for converting rulenames to name&rarr;ruleindex map.\n *\/\n","spaces":"\/** \n * @since 4.6 \n *\/\n","count":"\/** \n * @since 4.6 \n *\/\n"}}
{"Predicate":{}}
{"ParseCancellationException":{}}
{"IntervalSet":{"add":"\/** \n * Add interval; i.e., add all integers from a to b to set. If b&lt;a, do nothing. Keep list in sorted order (by left range value). If overlap, combine ranges.  For example, If this is {1..5, 10..20}, adding 6..7 yields {1..5, 6..7, 10..20}.  Adding 4..8 yields {1..8, 10..20}.\n *\/\n","or":"\/** \n * combine all sets in the array returned the or'd value \n *\/\n","subtract":"\/** \n * Compute the set difference between two interval sets. The specific operation is  {@code left - right}. If either of the input sets is {@code null}, it is treated as though it was an empty set.\n *\/\n","elementName":"\/** \n * @deprecated Use {@link #elementName(Vocabulary,int)} instead.\n *\/\n","contains":"\/** \n * {@inheritDoc} \n *\/\n","getMaxElement":"\/** \n * Returns the maximum value contained in the set if not isNil().\n * @return the maximum value contained in the set.\n * @throws RuntimeException if set is empty\n *\/\n","getIntervals":"\/** \n * Return a list of Interval objects. \n *\/\n","getMinElement":"\/** \n * Returns the minimum value contained in the set if not isNil().\n * @return the minimum value contained in the set.\n * @throws RuntimeException if set is empty\n *\/\n","and":"\/** \n * {@inheritDoc} \n *\/\n","of":"\/** \n * Create a set with all ints within range [a..b] (inclusive) \n *\/\n","equals":"\/** \n * Are two IntervalSets equal?  Because all intervals are sorted and disjoint, equals is a simple linear walk over both lists to make sure they are the same.  Interval.equals() is used by the List.equals() method to check the ranges.\n *\/\n","get":"\/** \n * Get the ith element of ordered set.  Used only by RandomPhrase so don't bother to implement if you're not doing that for a new ANTLR code gen target.\n *\/\n","isNil":"\/** \n * {@inheritDoc} \n *\/\n","toString":"\/** \n * @deprecated Use {@link #toString(Vocabulary)} instead.\n *\/\n","complement":"\/** \n * {@inheritDoc} \n *\/\n"}}
{"AbstractEqualityComparator":{}}
{"IntegerList":{"toCharArray":"\/** \n * Convert the list to a UTF-16 encoded char array. If all values are less than the 0xFFFF 16-bit code point limit then this is just a char array of 16-bit char as usual. For values in the supplementary range, encode them as two UTF-16 code units.\n *\/\n","hashCode":"\/** \n * Returns the hash code value for this list. <p>This implementation uses exactly the code that is used to define the list hash function in the documentation for the  {@link List#hashCode}method.<\/p>\n * @return the hash code value for this list\n *\/\n","equals":"\/** \n * Compares the specified object with this list for equality.  Returns {@code true} if and only if the specified object is also an {@link IntegerList}, both lists have the same size, and all corresponding pairs of elements in the two lists are equal.  In other words, two lists are defined to be equal if they contain the same elements in the same order. <p> This implementation first checks if the specified object is this list. If so, it returns  {@code true}; if not, it checks if the specified object is an  {@link IntegerList}. If not, it returns  {@code false}; if so, it checks the size of both lists. If the lists are not the same size, it returns  {@code false}; otherwise it iterates over both lists, comparing corresponding pairs of elements.  If any comparison returns  {@code false}, this method returns  {@code false}.\n * @param o the object to be compared for equality with this list\n * @return {@code true} if the specified object is equal to this list\n *\/\n","toString":"\/** \n * Returns a string representation of this list.\n *\/\n"}}
{"InterpreterDataReader":{"parseFile":"\/** \n * The structure of the data file is very simple. Everything is line based with empty lines separating the different parts. For lexers the layout is: token literal names: ... token symbolic names: ... rule names: ... channel names: ... mode names: ... atn: <a single line with comma separated int values> enclosed in a pair of squared brackets. Data for a parser does not contain channel and mode names.\n *\/\n"}}
{"FlexibleHashMap":{}}
{"Triple":{}}
{"IntegerStack":{}}
{"DoubleKeyMap":{"values":"\/** \n * Get all values associated with primary key \n *\/\n","keySet":"\/** \n * get all secondary keys associated with a primary key \n *\/\n"}}
{"OrderedHashSet":{"add":"\/** \n * Add a value to list; keep in hashtable for consistency also; Key is object itself.  Good for say asking if a certain string is in a list of strings.\n *\/\n","set":"\/** \n * Replace an existing value with a new value; updates the element list and the hash table, but not the key as that has not changed.\n *\/\n","elements":"\/** \n * Return the List holding list of table elements.  Note that you are NOT getting a copy so don't write to the list.\n *\/\n"}}
{"MurmurHash":{"hashCode":"\/** \n * Utility function to compute the hash code of an array using the MurmurHash algorithm.\n * @param < T > the array element type\n * @param data the array data\n * @param seed the seed for the MurmurHash algorithm\n * @return the hash code of the data\n *\/\n","update":"\/** \n * Update the intermediate hash value for the next input  {@code value}.\n * @param hash the intermediate hash value\n * @param value the value to add to the current hash\n * @return the updated intermediate hash value\n *\/\n","finish":"\/** \n * Apply the final computation steps to the intermediate value  {@code hash}to form the final result of the MurmurHash 3 hash function.\n * @param hash the intermediate hash value\n * @param numberOfWords the number of integer values added to the hash\n * @return the final hash result\n *\/\n","initialize":"\/** \n * Initialize the hash using the specified  {@code seed}.\n * @param seed the seed\n * @return the intermediate hash value\n *\/\n"}}
{"NotNull":{}}
{"MultiMap":{}}
{"Tree":{"getChildCount":"\/** \n * How many children are there? If there is none, then this node represents a leaf node.\n *\/\n","getPayload":"\/** \n * This method returns whatever object represents the data at this note. For example, for parse trees, the payload can be a  {@link Token} representinga leaf node or a  {@link RuleContext} object representing a ruleinvocation. For abstract syntax trees (ASTs), this is a  {@link Token}object.\n *\/\n","getParent":"\/** \n * The parent of this node. If the return value is null, then this node is the root of the tree.\n *\/\n","getChild":"\/** \n * If there are children, get the  {@code i}th value indexed from 0. \n *\/\n","toStringTree":"\/** \n * Print out a whole tree, not just a node, in LISP format {@code (root child1 .. childN)}. Print just a node if this is a leaf.\n *\/\n"}}
{"XPathTokenElement":{}}
{"XPath":{"getXPathElement":"\/** \n * Convert word like  {@code *} or {@code ID} or {@code expr} to a pathelement.  {@code anywhere} is {@code true} if {@code \/\/} precedes theword.\n *\/\n","evaluate":"\/** \n * Return a list of all nodes starting at  {@code t} as root that satisfy thepath. The root  {@code \/} is relative to the node passed to{@link #evaluate}.\n *\/\n"}}
{"XPathLexerErrorListener":{}}
{"XPathLexer":{}}
{"XPathRuleAnywhereElement":{}}
{"XPathRuleElement":{}}
{"XPathWildcardAnywhereElement":{}}
{"XPathTokenAnywhereElement":{}}
{"XPathElement":{"XPathElement":"\/** \n * Construct element like  {@code \/ID} or {@code ID} or {@code \/*} etc...op is null if just node\n *\/\n","evaluate":"\/** \n * Given tree rooted at  {@code t} return all nodes matched by this pathelement.\n *\/\n"}}
{"XPathWildcardElement":{}}
{"SyntaxTree":{"getSourceInterval":"\/** \n * Return an  {@link Interval} indicating the index in the{@link TokenStream} of the first and last token associated with thissubtree. If this node is a leaf, then the interval represents a single token and has interval i..i for token index i. <p>An interval of i..i-1 indicates an empty interval at position i in the input stream, where 0 &lt;= i &lt;= the size of the input token stream.  Currently, the code base can only have i=0..n-1 but in concept one could have an empty interval after EOF. <\/p> <p>If source interval is unknown, this returns  {@link Interval#INVALID}.<\/p> <p>As a weird special case, the source interval for rules matched after EOF is unspecified.<\/p>\n *\/\n"}}
{"ParseTreeProperty":{}}
{"Trees":{"getAncestors":"\/** \n * Return a list of all ancestors of this node.  The first node of list is the root and the last is the parent of this node.\n * @since 4.5.1\n *\/\n","isAncestorOf":"\/** \n * Return true if t is u's parent or a node on path to root from u. Use == not equals().\n * @since 4.5.1\n *\/\n","getChildren":"\/** \n * Return ordered list of all children of this node \n *\/\n","getDescendants":"\/** \n * Get all descendents; includes t itself.\n * @since 4.5.1\n *\/\n","findNodeSuchThat":"\/** \n * Return first node satisfying the pred\n * @since 4.5.1\n *\/\n","stripChildrenOutOfRange":"\/** \n * Replace any subtree siblings of root that are completely to left or right of lookahead range with a CommonToken(Token.INVALID_TYPE,\"...\") node. The source interval for t is not altered to suit smaller range! WARNING: destructive to t.\n * @since 4.5.1\n *\/\n","getRootOfSubtreeEnclosingRegion":"\/** \n * Find smallest subtree of t enclosing range startTokenIndex..stopTokenIndex inclusively using postorder traversal.  Recursive depth-first-search.\n * @since 4.5.1\n *\/\n","toStringTree":"\/** \n * Print out a whole tree in LISP form.  {@link #getNodeText} is used on thenode payloads to get the text for the nodes.\n *\/\n","descendants":"\/** \n * @deprecated \n *\/\n"}}
{"IterativeParseTreeWalker":{}}
{"ParseTreeWalker":{"enterRule":"\/** \n * The discovery of a rule node, involves sending two events: the generic {@link ParseTreeListener#enterEveryRule} and a{@link RuleContext}-specific event. First we trigger the generic and then the rule specific. We to them in reverse order upon finishing the node.\n *\/\n"}}
{"ParseTreeVisitor":{"visitErrorNode":"\/** \n * Visit an error node, and return a user-defined result of the operation.\n * @param node The {@link ErrorNode} to visit.\n * @return The result of visiting the node.\n *\/\n","visitTerminal":"\/** \n * Visit a terminal node, and return a user-defined result of the operation.\n * @param node The {@link TerminalNode} to visit.\n * @return The result of visiting the node.\n *\/\n","visit":"\/** \n * Visit a parse tree, and return a user-defined result of the operation.\n * @param tree The {@link ParseTree} to visit.\n * @return The result of visiting the parse tree.\n *\/\n","visitChildren":"\/** \n * Visit the children of a node, and return a user-defined result of the operation.\n * @param node The {@link RuleNode} whose children should be visited.\n * @return The result of visiting the children of the node.\n *\/\n"}}
{"ErrorNodeImpl":{}}
{"AbstractParseTreeVisitor":{"visitErrorNode":"\/** \n * {@inheritDoc}<p>The default implementation returns the result of {@link #defaultResult defaultResult}.<\/p>\n *\/\n","aggregateResult":"\/** \n * Aggregates the results of visiting multiple children of a node. After either all children are visited or  {@link #shouldVisitNextChild} returns{@code false}, the aggregate value is returned as the result of {@link #visitChildren}. <p>The default implementation returns  {@code nextResult}, meaning {@link #visitChildren} will return the result of the last child visited(or return the initial value if the node has no children).<\/p>\n * @param aggregate The previous aggregate value. In the defaultimplementation, the aggregate value is initialized to {@link #defaultResult}, which is passed as the  {@code aggregate} argumentto this method after the first child node is visited.\n * @param nextResult The result of the immediately preceeding call to visita child node.\n * @return The updated aggregate result.\n *\/\n","visitTerminal":"\/** \n * {@inheritDoc}<p>The default implementation returns the result of {@link #defaultResult defaultResult}.<\/p>\n *\/\n","visit":"\/** \n * {@inheritDoc}<p>The default implementation calls  {@link ParseTree#accept} on thespecified tree.<\/p>\n *\/\n","defaultResult":"\/** \n * Gets the default value returned by visitor methods. This value is returned by the default implementations of {@link #visitTerminal visitTerminal},  {@link #visitErrorNode visitErrorNode}. The default implementation of  {@link #visitChildren visitChildren}initializes its aggregate result to this value. <p>The base implementation returns  {@code null}.<\/p>\n * @return The default value returned by visitor methods.\n *\/\n","visitChildren":"\/** \n * {@inheritDoc}<p>The default implementation initializes the aggregate result to {@link #defaultResult defaultResult()}. Before visiting each child, it calls  {@link #shouldVisitNextChild shouldVisitNextChild}; if the result is  {@code false} no more children are visited and the current aggregateresult is returned. After visiting a child, the aggregate result is updated by calling  {@link #aggregateResult aggregateResult} with theprevious aggregate result and the result of visiting the child.<\/p> <p>The default implementation is not safe for use in visitors that modify the tree structure. Visitors that modify the tree should override this method to behave properly in respect to the specific algorithm in use.<\/p>\n *\/\n","shouldVisitNextChild":"\/** \n * This method is called after visiting each child in {@link #visitChildren}. This method is first called before the first child is visited; at that point  {@code currentResult} will be the initialvalue (in the default implementation, the initial value is returned by a call to  {@link #defaultResult}. This method is not called after the last child is visited. <p>The default implementation always returns  {@code true}, indicating that {@code visitChildren} should only return after all children are visited.One reason to override this method is to provide a \"short circuit\" evaluation option for situations where the result of visiting a single child has the potential to determine the result of the visit operation as a whole.<\/p>\n * @param node The {@link RuleNode} whose children are currently beingvisited.\n * @param currentResult The current aggregate result of the children visitedto the current point.\n * @return {@code true} to continue visiting children. Otherwise return{@code false} to stop visiting children and immediately return thecurrent aggregate result from  {@link #visitChildren}.\n *\/\n"}}
{"ParseTree":{"getText":"\/** \n * Return the combined text of all leaf nodes. Does not get any off-channel tokens (if any) so won't return whitespace and comments if they are sent to parser on hidden channel.\n *\/\n","setParent":"\/** \n * Set the parent for this node. This is not backward compatible as it changes the interface but no one was able to create custom nodes anyway so I'm adding as it improves internal code quality. One could argue for a restructuring of the class\/interface hierarchy so that setParent, addChild are moved up to Tree but that's a major change. So I'll do the minimal change, which is to add this method.\n * @since 4.7\n *\/\n","toStringTree":"\/** \n * Specialize toStringTree so that it can print out more information based upon the parser.\n *\/\n","accept":"\/** \n * The  {@link ParseTreeVisitor} needs a double dispatch method. \n *\/\n"}}
{"TerminalNodeImpl":{}}
{"ParseTreeListener":{}}
{"RuleNode":{}}
{"TextChunk":{"getText":"\/** \n * Gets the raw text of this chunk.\n * @return The text of the chunk.\n *\/\n","TextChunk":"\/** \n * Constructs a new instance of  {@link TextChunk} with the specified text.\n * @param text The text of this chunk.\n * @exception IllegalArgumentException if {@code text} is {@code null}.\n *\/\n","toString":"\/** \n * {@inheritDoc}<p>The implementation for  {@link TextChunk} returns the result of{@link #getText()} in single quotes.<\/p>\n *\/\n"}}
{"TagChunk":{"TagChunk":"\/** \n * Construct a new instance of  {@link TagChunk} using the specified labeland tag.\n * @param label The label for the tag. If this is {@code null}, the {@link TagChunk} represents an unlabeled tag.\n * @param tag The tag, which should be the name of a parser rule or tokentype.\n * @exception IllegalArgumentException if {@code tag} is {@code null} orempty.\n *\/\n","getLabel":"\/** \n * Get the label, if any, assigned to this chunk.\n * @return The label assigned to this chunk, or {@code null} if no label isassigned to the chunk.\n *\/\n","toString":"\/** \n * This method returns a text representation of the tag chunk. Labeled tags are returned in the form  {@code label:tag}, and unlabeled tags are returned as just the tag name.\n *\/\n","getTag":"\/** \n * Get the tag for this chunk.\n * @return The tag for the chunk.\n *\/\n"}}
{"RuleTagToken":{"getLabel":"\/** \n * Gets the label associated with the rule tag.\n * @return The name of the label associated with the rule tag, or{@code null} if this is an unlabeled rule tag.\n *\/\n","getStopIndex":"\/** \n * {@inheritDoc}<p>The implementation for  {@link RuleTagToken} always returns -1.<\/p>\n *\/\n","RuleTagToken":"\/** \n * Constructs a new instance of  {@link RuleTagToken} with the specified rulename, bypass token type, and label.\n * @param ruleName The name of the parser rule this rule tag matches.\n * @param bypassTokenType The bypass token type assigned to the parser rule.\n * @param label The label associated with the rule tag, or {@code null} ifthe rule tag is unlabeled.\n * @exception IllegalArgumentException if {@code ruleName} is {@code null}or empty.\n *\/\n","getRuleName":"\/** \n * Gets the name of the rule associated with this rule tag.\n * @return The name of the parser rule associated with this rule tag.\n *\/\n","getStartIndex":"\/** \n * {@inheritDoc}<p>The implementation for  {@link RuleTagToken} always returns -1.<\/p>\n *\/\n","getText":"\/** \n * {@inheritDoc}<p>This method returns the rule tag formatted with  {@code <} and {@code >}delimiters.<\/p>\n *\/\n","getCharPositionInLine":"\/** \n * {@inheritDoc}<p>The implementation for  {@link RuleTagToken} always returns -1.<\/p>\n *\/\n","getLine":"\/** \n * {@inheritDoc}<p>The implementation for  {@link RuleTagToken} always returns 0.<\/p>\n *\/\n","getInputStream":"\/** \n * {@inheritDoc}<p>The implementation for  {@link RuleTagToken} always returns {@code null}.<\/p>\n *\/\n","getChannel":"\/** \n * {@inheritDoc}<p>Rule tag tokens are always placed on the  {@link #DEFAULT_CHANNEL}.<\/p>\n *\/\n","getType":"\/** \n * {@inheritDoc}<p>Rule tag tokens have types assigned according to the rule bypass transitions created during ATN deserialization.<\/p>\n *\/\n","toString":"\/** \n * {@inheritDoc}<p>The implementation for  {@link RuleTagToken} returns a string of the form{@code ruleName:bypassTokenType}.<\/p>\n *\/\n","getTokenIndex":"\/** \n * {@inheritDoc}<p>The implementation for  {@link RuleTagToken} always returns -1.<\/p>\n *\/\n","getTokenSource":"\/** \n * {@inheritDoc}<p>The implementation for  {@link RuleTagToken} always returns {@code null}.<\/p>\n *\/\n"}}
{"ParseTreePattern":{"getPatternRuleIndex":"\/** \n * Get the parser rule which serves as the outermost rule for the tree pattern.\n * @return The parser rule which serves as the outermost rule for the treepattern.\n *\/\n","getMatcher":"\/** \n * Get the  {@link ParseTreePatternMatcher} which created this tree pattern.\n * @return The {@link ParseTreePatternMatcher} which created this treepattern.\n *\/\n","match":"\/** \n * Match a specific parse tree against this tree pattern.\n * @param tree The parse tree to match against this tree pattern.\n * @return A {@link ParseTreeMatch} object describing the result of thematch operation. The  {@link ParseTreeMatch#succeeded()} method can beused to determine whether or not the match was successful.\n *\/\n","ParseTreePattern":"\/** \n * Construct a new instance of the  {@link ParseTreePattern} class.\n * @param matcher The {@link ParseTreePatternMatcher} which created thistree pattern.\n * @param pattern The tree pattern in concrete syntax form.\n * @param patternRuleIndex The parser rule which serves as the root of thetree pattern.\n * @param patternTree The tree pattern in {@link ParseTree} form.\n *\/\n","getPattern":"\/** \n * Get the tree pattern in concrete syntax form.\n * @return The tree pattern in concrete syntax form.\n *\/\n","matches":"\/** \n * Determine whether or not a parse tree matches this tree pattern.\n * @param tree The parse tree to match against this tree pattern.\n * @return {@code true} if {@code tree} is a match for the current treepattern; otherwise,  {@code false}.\n *\/\n","findAll":"\/** \n * Find all nodes using XPath and then try to match those subtrees against this tree pattern.\n * @param tree The {@link ParseTree} to match against this pattern.\n * @param xpath An expression matching the nodes\n * @return A collection of {@link ParseTreeMatch} objects describing thesuccessful matches. Unsuccessful matches are omitted from the result, regardless of the reason for the failure.\n *\/\n","getPatternTree":"\/** \n * Get the tree pattern as a  {@link ParseTree}. The rule and token tags from the pattern are present in the parse tree as terminal nodes with a symbol of type  {@link RuleTagToken} or {@link TokenTagToken}.\n * @return The tree pattern as a {@link ParseTree}.\n *\/\n"}}
{"ParseTreePatternMatcher":{"matchImpl":"\/** \n * Recursively walk  {@code tree} against {@code patternTree}, filling {@code match.}{@link ParseTreeMatch#labels labels}.\n * @return the first node encountered in {@code tree} which does not matcha corresponding node in  {@code patternTree}, or  {@code null} if the matchwas successful. The specific node returned depends on the matching algorithm used by the implementation, and may be overridden.\n *\/\n","split":"\/** \n * Split  {@code <ID> = <e:expr> ;} into 4 chunks for tokenizing by {@link #tokenize}. \n *\/\n","compile":"\/** \n * For repeated use of a tree pattern, compile it to a {@link ParseTreePattern} using this method.\n *\/\n","getRuleTagToken":"\/** \n * Is  {@code t} {@code (expr <expr>)} subtree? \n *\/\n","ParseTreePatternMatcher":"\/** \n * Constructs a  {@link ParseTreePatternMatcher} or from a {@link Lexer} and{@link Parser} object. The lexer input stream is altered for tokenizingthe tree patterns. The parser is used as a convenient mechanism to get the grammar name, plus token, rule names.\n *\/\n","getParser":"\/** \n * Used to collect to the grammar file name, token names, rule names for used to parse the pattern into a parse tree.\n *\/\n","match":"\/** \n * Compare  {@code pattern} matched against {@code tree} and return a{@link ParseTreeMatch} object that contains the matched elements, or thenode at which the match failed. Pass in a compiled pattern instead of a string representation of a tree pattern.\n *\/\n","getLexer":"\/** \n * Used to convert the tree pattern string into a series of tokens. The input stream is reset.\n *\/\n","matches":"\/** \n * Does  {@code pattern} matched as rule patternRuleIndex match tree? Pass in acompiled pattern instead of a string representation of a tree pattern.\n *\/\n","setDelimiters":"\/** \n * Set the delimiters used for marking rule and token tags within concrete syntax used by the tree pattern parser.\n * @param start The start delimiter.\n * @param stop The stop delimiter.\n * @param escapeLeft The escape sequence to use for escaping a start or stop delimiter.\n * @exception IllegalArgumentException if {@code start} is {@code null} or empty.\n * @exception IllegalArgumentException if {@code stop} is {@code null} or empty.\n *\/\n"}}
{"Chunk":{}}
{"ParseTreeMatch":{"getMismatchedNode":"\/** \n * Get the node at which we first detected a mismatch.\n * @return the node at which we first detected a mismatch, or {@code null}if the match was successful.\n *\/\n","getTree":"\/** \n * Get the parse tree we are trying to match to a pattern.\n * @return The {@link ParseTree} we are trying to match to a pattern.\n *\/\n","getLabels":"\/** \n * Return a mapping from label &rarr; [list of nodes]. <p>The map includes special entries corresponding to the names of rules and tokens referenced in tags in the original pattern. For additional information, see the description of  {@link #getAll(String)}.<\/p>\n * @return A mapping from labels to parse tree nodes. If the parse treepattern did not contain any rule or token tags, this map will be empty.\n *\/\n","getAll":"\/** \n * Return all nodes matching a rule or token tag with the specified label. <p>If the  {@code label} is the name of a parser rule or token in thegrammar, the resulting list will contain both the parse trees matching rule or tags explicitly labeled with the label and the complete set of parse trees matching the labeled and unlabeled tags in the pattern for the parser rule or token. For example, if  {@code label} is {@code \"foo\"}, the result will contain <em>all<\/em> of the following.<\/p> <ul> <li>Parse tree nodes matching tags of the form  {@code <foo:anyRuleName>} and{@code <foo:AnyTokenName>}.<\/li> <li>Parse tree nodes matching tags of the form  {@code <anyLabel:foo>}.<\/li> <li>Parse tree nodes matching tags of the form  {@code <foo>}.<\/li> <\/ul>\n * @param label The label.\n * @return A collection of all {@link ParseTree} nodes matching tags withthe specified  {@code label}. If no nodes matched the label, an empty list is returned.\n *\/\n","get":"\/** \n * Get the last node associated with a specific  {@code label}. <p>For example, for pattern  {@code <id:ID>},  {@code get(\"id\")} returns thenode matched for that  {@code ID}. If more than one node matched the specified label, only the last is returned. If there is no node associated with the label, this returns  {@code null}.<\/p> <p>Pattern tags like  {@code <ID>} and {@code <expr>} without labels areconsidered to be labeled with  {@code ID} and {@code expr}, respectively.<\/p>\n * @param label The label to check.\n * @return The last {@link ParseTree} to match a tag with the specifiedlabel, or  {@code null} if no parse tree matched a tag with the label.\n *\/\n","toString":"\/** \n * {@inheritDoc}\n *\/\n","getPattern":"\/** \n * Get the tree pattern we are matching against.\n * @return The tree pattern we are matching against.\n *\/\n","ParseTreeMatch":"\/** \n * Constructs a new instance of  {@link ParseTreeMatch} from the specifiedparse tree and pattern.\n * @param tree The parse tree to match against the pattern.\n * @param pattern The parse tree pattern.\n * @param labels A mapping from label names to collections of{@link ParseTree} objects located by the tree pattern matching process.\n * @param mismatchedNode The first node which failed to match the treepattern during the matching process.\n * @exception IllegalArgumentException if {@code tree} is {@code null}\n * @exception IllegalArgumentException if {@code pattern} is {@code null}\n * @exception IllegalArgumentException if {@code labels} is {@code null}\n *\/\n","succeeded":"\/** \n * Gets a value indicating whether the match operation succeeded.\n * @return {@code true} if the match operation succeeded; otherwise,{@code false}.\n *\/\n"}}
{"TokenTagToken":{"getLabel":"\/** \n * Gets the label associated with the rule tag.\n * @return The name of the label associated with the rule tag, or{@code null} if this is an unlabeled rule tag.\n *\/\n","getText":"\/** \n * {@inheritDoc}<p>The implementation for  {@link TokenTagToken} returns the token tagformatted with  {@code <} and {@code >} delimiters.<\/p>\n *\/\n","getTokenName":"\/** \n * Gets the token name.\n * @return The token name.\n *\/\n","TokenTagToken":"\/** \n * Constructs a new instance of  {@link TokenTagToken} with the specifiedtoken name, type, and label.\n * @param tokenName The token name.\n * @param type The token type.\n * @param label The label associated with the token tag, or {@code null} ifthe token tag is unlabeled.\n *\/\n","toString":"\/** \n * {@inheritDoc}<p>The implementation for  {@link TokenTagToken} returns a string of the form{@code tokenName:type}.<\/p>\n *\/\n"}}
{"ErrorNode":{}}
{"TerminalNode":{}}
{"RuleContext":{"getText":"\/** \n * Return the combined text of all child nodes. This method only considers tokens which have been added to the parse tree. <p> Since tokens on hidden channels (e.g. whitespace or comments) are not added to the parse trees, they will not appear in the output of this method.\n *\/\n","getAltNumber":"\/** \n * For rule associated with this parse tree internal node, return the outer alternative number used to match the input. Default implementation does not compute nor store this alt num. Create a subclass of ParserRuleContext with backing field and set option contextSuperClass. to set it.\n * @since 4.5.3\n *\/\n","isEmpty":"\/** \n * A context is empty if there is no invoking state; meaning nobody called current context.\n *\/\n","setParent":"\/** \n * @since 4.7. {@see ParseTree#setParent} comment \n *\/\n","toStringTree":"\/** \n * Print out a whole tree, not just a node, in LISP format (root child1 .. childN). Print just a node if this is a leaf.\n *\/\n","setAltNumber":"\/** \n * Set the outer alternative number for this context node. Default implementation does nothing to avoid backing field overhead for trees that don't need it.  Create a subclass of ParserRuleContext with backing field and set option contextSuperClass.\n * @since 4.5.3\n *\/\n"}}
{"DefaultErrorStrategy":{"singleTokenInsertion":"\/** \n * This method implements the single-token insertion inline error recovery strategy. It is called by  {@link #recoverInline} if the single-tokendeletion strategy fails to recover from the mismatched input. If this method returns  {@code true},  {@code recognizer} will be in error recoverymode. <p>This method determines whether or not single-token insertion is viable by checking if the  {@code LA(1)} input symbol could be successfully matchedif it were instead the  {@code LA(2)} symbol. If this method returns{@code true}, the caller is responsible for creating and inserting a token with the correct type to produce this behavior.<\/p>\n * @param recognizer the parser instance\n * @return {@code true} if single-token insertion is a viable recoverystrategy for the current mismatched input, otherwise  {@code false}\n *\/\n","recover":"\/** \n * {@inheritDoc}<p>The default implementation resynchronizes the parser by consuming tokens until we find one in the resynchronization set--loosely the set of tokens that can follow the current rule.<\/p>\n *\/\n","inErrorRecoveryMode":"\/** \n * {@inheritDoc}\n *\/\n","reportError":"\/** \n * {@inheritDoc}<p>The default implementation returns immediately if the handler is already in error recovery mode. Otherwise, it calls  {@link #beginErrorCondition}and dispatches the reporting task based on the runtime type of  {@code e}according to the following table.<\/p> <ul> <li> {@link NoViableAltException}: Dispatches the call to {@link #reportNoViableAlternative}<\/li> <li> {@link InputMismatchException}: Dispatches the call to {@link #reportInputMismatch}<\/li> <li> {@link FailedPredicateException}: Dispatches the call to {@link #reportFailedPredicate}<\/li> <li>All other types: calls  {@link Parser#notifyErrorListeners} to reportthe exception<\/li> <\/ul>\n *\/\n","beginErrorCondition":"\/** \n * This method is called to enter error recovery mode when a recognition exception is reported.\n * @param recognizer the parser instance\n *\/\n","sync":"\/** \n * The default implementation of  {@link ANTLRErrorStrategy#sync} makes surethat the current lookahead symbol is consistent with what were expecting at this point in the ATN. You can call this anytime but ANTLR only generates code to check before subrules\/loops and each iteration. <p>Implements Jim Idle's magic sync mechanism in closures and optional subrules. E.g.,<\/p> <pre> a : sync ( stuff sync )* ; sync : {consume to what can follow sync} ; <\/pre> At the start of a sub rule upon error,  {@link #sync} performs singletoken deletion, if possible. If it can't do that, it bails on the current rule and uses the default error recovery, which consumes until the resynchronization set of the current rule. <p>If the sub rule is optional ( {@code (...)?},  {@code (...)*}, or block with an empty alternative), then the expected set includes what follows the subrule.<\/p> <p>During loop iteration, it consumes until it sees a token that can start a sub rule or what follows loop. Yes, that is pretty aggressive. We opt to stay in the loop as long as possible.<\/p> <p><strong>ORIGINS<\/strong><\/p> <p>Previous versions of ANTLR did a poor job of their recovery within loops. A single mismatch token or missing token would force the parser to bail out of the entire rules surrounding the loop. So, for rule<\/p> <pre> classDef : 'class' ID '{' member* '}' <\/pre> input with an extra token between members would force the parser to consume until it found the next class definition rather than the next member definition of the current class. <p>This functionality cost a little bit of effort because the parser has to compare token set at the start of the loop and at each iteration. If for some reason speed is suffering for you, you can turn off this functionality by simply overriding this method as a blank { }.<\/p>\n *\/\n","reportNoViableAlternative":"\/** \n * This is called by  {@link #reportError} when the exception is a{@link NoViableAltException}.\n * @see #reportError\n * @param recognizer the parser instance\n * @param e the recognition exception\n *\/\n","reportMissingToken":"\/** \n * This method is called to report a syntax error which requires the insertion of a missing token into the input stream. At the time this method is called, the missing token has not yet been inserted. When this method returns,  {@code recognizer} is in error recovery mode.<p>This method is called when  {@link #singleTokenInsertion} identifiessingle-token insertion as a viable recovery strategy for a mismatched input error.<\/p> <p>The default implementation simply returns if the handler is already in error recovery mode. Otherwise, it calls  {@link #beginErrorCondition} toenter error recovery mode, followed by calling {@link Parser#notifyErrorListeners}.<\/p>\n * @param recognizer the parser instance\n *\/\n","recoverInline":"\/** \n * {@inheritDoc}<p>The default implementation attempts to recover from the mismatched input by using single token insertion and deletion as described below. If the recovery attempt fails, this method throws an {@link InputMismatchException}.<\/p> <p><strong>EXTRA TOKEN<\/strong> (single token deletion)<\/p> <p> {@code LA(1)} is not what we are looking for. If {@code LA(2)} has theright token, however, then assume  {@code LA(1)} is some extra spurioustoken and delete it. Then consume and return the next token (which was the  {@code LA(2)} token) as the successful result of the match operation.<\/p><p>This recovery strategy is implemented by  {@link #singleTokenDeletion}.<\/p> <p><strong>MISSING TOKEN<\/strong> (single token insertion)<\/p> <p>If current token (at  {@code LA(1)}) is consistent with what could come after the expected  {@code LA(1)} token, then assume the token is missingand use the parser's  {@link TokenFactory} to create it on the fly. The\"insertion\" is performed by returning the created token as the successful result of the match operation.<\/p> <p>This recovery strategy is implemented by  {@link #singleTokenInsertion}.<\/p> <p><strong>EXAMPLE<\/strong><\/p> <p>For example, Input  {@code i=(3;} is clearly missing the {@code ')'}. When the parser returns from the nested call to  {@code expr}, it will have call chain:<\/p> <pre> stat &rarr; expr &rarr; atom <\/pre> and it will be trying to match the  {@code ')'} at this point in thederivation: <pre> =&gt; ID '=' '(' INT ')' ('+' atom)* ';' ^ <\/pre> The attempt to match  {@code ')'} will fail when it sees {@code ';'} andcall  {@link #recoverInline}. To recover, it sees that  {@code LA(1)==';'}is in the set of tokens that can follow the  {@code ')'} token referencein rule  {@code atom}. It can assume that you forgot the  {@code ')'}.\n *\/\n","singleTokenDeletion":"\/** \n * This method implements the single-token deletion inline error recovery strategy. It is called by  {@link #recoverInline} to attempt to recoverfrom mismatched input. If this method returns null, the parser and error handler state will not have changed. If this method returns non-null, {@code recognizer} will <em>not<\/em> be in error recovery mode since thereturned token was a successful match. <p>If the single-token deletion is successful, this method calls {@link #reportUnwantedToken} to report the error, followed by{@link Parser#consume} to actually \"delete\" the extraneous token. Then,before returning  {@link #reportMatch} is called to signal a successfulmatch.<\/p>\n * @param recognizer the parser instance\n * @return the successfully matched {@link Token} instance if single-tokendeletion successfully recovers from the mismatched input, otherwise {@code null}\n *\/\n","getTokenErrorDisplay":"\/** \n * How should a token be displayed in an error message? The default is to display just the text, but during development you might want to have a lot of information spit out.  Override in that case to use t.toString() (which, for CommonToken, dumps everything about the token). This is better than forcing you to override a method in your token objects because you don't have to go modify your lexer so that it creates a new Java type.\n *\/\n","endErrorCondition":"\/** \n * This method is called to leave error recovery mode after recovering from a recognition exception.\n * @param recognizer\n *\/\n","reportUnwantedToken":"\/** \n * This method is called to report a syntax error which requires the removal of a token from the input stream. At the time this method is called, the erroneous symbol is current  {@code LT(1)} symbol and has not yet beenremoved from the input stream. When this method returns, {@code recognizer} is in error recovery mode.<p>This method is called when  {@link #singleTokenDeletion} identifiessingle-token deletion as a viable recovery strategy for a mismatched input error.<\/p> <p>The default implementation simply returns if the handler is already in error recovery mode. Otherwise, it calls  {@link #beginErrorCondition} toenter error recovery mode, followed by calling {@link Parser#notifyErrorListeners}.<\/p>\n * @param recognizer the parser instance\n *\/\n","reportMatch":"\/** \n * {@inheritDoc}<p>The default implementation simply calls  {@link #endErrorCondition}.<\/p>\n *\/\n","consumeUntil":"\/** \n * Consume tokens until one matches the given token set. \n *\/\n","reset":"\/** \n * {@inheritDoc}<p>The default implementation simply calls  {@link #endErrorCondition} toensure that the handler is not in error recovery mode.<\/p>\n *\/\n","getMissingSymbol":"\/** \n * Conjure up a missing token during error recovery. The recognizer attempts to recover from single missing symbols. But, actions might refer to that missing symbol. For example, x=ID {f($x);}. The action clearly assumes that there has been an identifier matched previously and that $x points at that token. If that token is missing, but the next token in the stream is what we want we assume that this token is missing and we keep going. Because we have to return some token to replace the missing token, we have to conjure one up. This method gives the user control over the tokens returned for missing tokens. Mostly, you will want to create something special for identifier tokens. For literals such as '{' and ',', the default action in the parser or tree parser works. It simply creates a CommonToken of the appropriate type. The text will be the token. If you change what tokens must be created by the lexer, override this method to create the appropriate tokens.\n *\/\n","reportInputMismatch":"\/** \n * This is called by  {@link #reportError} when the exception is an{@link InputMismatchException}.\n * @see #reportError\n * @param recognizer the parser instance\n * @param e the recognition exception\n *\/\n","reportFailedPredicate":"\/** \n * This is called by  {@link #reportError} when the exception is a{@link FailedPredicateException}.\n * @see #reportError\n * @param recognizer the parser instance\n * @param e the recognition exception\n *\/\n"}}
{"TokenSource":{"getSourceName":"\/** \n * Gets the name of the underlying input source. This method returns a non-null, non-empty string. If such a name is not known, this method returns  {@link IntStream#UNKNOWN_SOURCE_NAME}.\n *\/\n","getTokenFactory":"\/** \n * Gets the  {@link TokenFactory} this token source is currently using forcreating  {@link Token} objects from the input.\n * @return The {@link TokenFactory} currently used by this token source.\n *\/\n","nextToken":"\/** \n * Return a  {@link Token} object from your input stream (usually a{@link CharStream}). Do not fail\/return upon lexing error; keep chewing on the characters until you get a good one; errors are not passed through to the parser.\n *\/\n","getCharPositionInLine":"\/** \n * Get the index into the current line for the current position in the input stream. The first character on a line has position 0.\n * @return The line number for the current position in the input stream, or-1 if the current token source does not track character positions.\n *\/\n","getLine":"\/** \n * Get the line number for the current position in the input stream. The first line in the input is line 1.\n * @return The line number for the current position in the input stream, or0 if the current token source does not track line numbers.\n *\/\n","setTokenFactory":"\/** \n * Set the  {@link TokenFactory} this token source should use for creating{@link Token} objects from the input.\n * @param factory The {@link TokenFactory} to use for creating tokens.\n *\/\n","getInputStream":"\/** \n * Get the  {@link CharStream} from which this token source is currentlyproviding tokens.\n * @return The {@link CharStream} associated with the current position inthe input, or  {@code null} if no input stream is available for the tokensource.\n *\/\n"}}
{"CommonTokenStream":{"CommonTokenStream":"\/** \n * Constructs a new  {@link CommonTokenStream} using the specified tokensource and filtering tokens to the specified channel. Only tokens whose {@link Token#getChannel} matches {@code channel} or have the{@link Token#getType} equal to {@link Token#EOF} will be returned by thetoken stream lookahead methods.\n * @param tokenSource The token source.\n * @param channel The channel to use for filtering tokens.\n *\/\n","getNumberOfOnChannelTokens":"\/** \n * Count EOF just once. \n *\/\n"}}
{"TokenFactory":{"create":"\/** \n * Generically useful \n *\/\n"}}
{"Parser":{"setTrace":"\/** \n * During a parse is sometimes useful to listen in on the rule entry and exit events as well as token matches. This is for quick and dirty debugging.\n *\/\n","getBuildParseTree":"\/** \n * Gets whether or not a complete parse tree will be constructed while parsing. This property is  {@code true} for a newly constructed parser.\n * @return {@code true} if a complete parse tree will be constructed whileparsing, otherwise  {@code false}\n *\/\n","dumpDFA":"\/** \n * For debugging and other purposes. \n *\/\n","createErrorNode":"\/** \n * How to create an error node, given a token, associated with a parent. Typically, the error node to create is not a function of the parent.\n * @since 4.7\n *\/\n","getRuleIndex":"\/** \n * Get a rule's index (i.e.,  {@code RULE_ruleName} field) or -1 if not found. \n *\/\n","getPrecedence":"\/** \n * Get the precedence level for the top-most precedence rule.\n * @return The precedence level for the top-most precedence rule, or -1 ifthe parser context is not nested within a precedence rule.\n *\/\n","createTerminalNode":"\/** \n * How to create a token leaf node associated with a parent. Typically, the terminal node to create is not a function of the parent.\n * @since 4.7\n *\/\n","pushNewRecursionContext":"\/** \n * Like  {@link #enterRule} but for recursive rules.Make the current context the child of the incoming localctx.\n *\/\n","consume":"\/** \n * Consume and return the  {@linkplain #getCurrentToken current symbol}. <p>E.g., given the following input with  {@code A} being the currentlookahead symbol, this function moves the cursor to  {@code B} and returns{@code A}.<\/p> <pre> A B ^ <\/pre> If the parser is not in error recovery mode, the consumed symbol is added to the parse tree using  {@link ParserRuleContext#addChild(TerminalNode)}, and {@link ParseTreeListener#visitTerminal} is called on any parse listeners.If the parser <em>is<\/em> in error recovery mode, the consumed symbol is added to the parse tree using  {@link #createErrorNode(ParserRuleContext,Token)} then{@link ParserRuleContext#addErrorNode(ErrorNode)} and{@link ParseTreeListener#visitErrorNode} is called on any parselisteners.\n *\/\n","triggerExitRuleEvent":"\/** \n * Notify any parse listeners of an exit rule event.\n * @see #addParseListener\n *\/\n","compileParseTreePattern":"\/** \n * The same as  {@link #compileParseTreePattern(String,int)} but specify a{@link Lexer} rather than trying to deduce it from this parser.\n *\/\n","getCurrentToken":"\/** \n * Match needs to return the current input symbol, which gets put into the label for the associated token ref; e.g., x=ID.\n *\/\n","setTokenStream":"\/** \n * Set the token stream and reset the parser. \n *\/\n","getATNWithBypassAlts":"\/** \n * The ATN with bypass alternatives is expensive to create so we create it lazily.\n * @throws UnsupportedOperationException if the current parser does notimplement the  {@link #getSerializedATN()} method.\n *\/\n","isExpectedToken":"\/** \n * Checks whether or not  {@code symbol} can follow the current state in theATN. The behavior of this method is equivalent to the following, but is implemented such that the complete context-sensitive follow set does not need to be explicitly constructed. <pre> return getExpectedTokens().contains(symbol); <\/pre>\n * @param symbol the symbol type to check\n * @return {@code true} if {@code symbol} can follow the current state inthe ATN, otherwise  {@code false}.\n *\/\n","setTrimParseTree":"\/** \n * Trim the internal lists of the parse tree during parsing to conserve memory. This property is set to  {@code false} by default for a newly constructed parser.\n * @param trimParseTrees {@code true} to trim the capacity of the {@link ParserRuleContext#children}list to its size after a rule is parsed.\n *\/\n","removeParseListeners":"\/** \n * Remove all parse listeners.\n * @see #addParseListener\n *\/\n","matchWildcard":"\/** \n * Match current input symbol as a wildcard. If the symbol type matches (i.e. has a value greater than 0),  {@link ANTLRErrorStrategy#reportMatch}and  {@link #consume} are called to complete the match process.<p>If the symbol type does not match, {@link ANTLRErrorStrategy#recoverInline} is called on the current errorstrategy to attempt recovery. If  {@link #getBuildParseTree} is{@code true} and the token index of the symbol returned by{@link ANTLRErrorStrategy#recoverInline} is -1, the symbol is added tothe parse tree by calling  {@link Parser#createErrorNode(ParserRuleContext,Token)}. then {@link ParserRuleContext#addErrorNode(ErrorNode)}<\/p>\n * @return the matched symbol\n * @throws RecognitionException if the current input symbol did not matcha wildcard and the error strategy could not recover from the mismatched symbol\n *\/\n","getExpectedTokens":"\/** \n * Computes the set of input symbols which could follow the current parser state and context, as given by  {@link #getState} and {@link #getContext}, respectively.\n * @see ATN#getExpectedTokens(int,RuleContext)\n *\/\n","getTrimParseTree":"\/** \n * @return {@code true} if the {@link ParserRuleContext#children} list is trimmedusing the default  {@link Parser.TrimToSizeListener} during the parse process.\n *\/\n","match":"\/** \n * Match current input symbol against  {@code ttype}. If the symbol type matches,  {@link ANTLRErrorStrategy#reportMatch} and {@link #consume} arecalled to complete the match process. <p>If the symbol type does not match, {@link ANTLRErrorStrategy#recoverInline} is called on the current errorstrategy to attempt recovery. If  {@link #getBuildParseTree} is{@code true} and the token index of the symbol returned by{@link ANTLRErrorStrategy#recoverInline} is -1, the symbol is added tothe parse tree by calling  {@link #createErrorNode(ParserRuleContext,Token)} then{@link ParserRuleContext#addErrorNode(ErrorNode)}.<\/p>\n * @param ttype the token type to match\n * @return the matched symbol\n * @throws RecognitionException if the current input symbol did not match{@code ttype} and the error strategy could not recover from themismatched symbol\n *\/\n","setTokenFactory":"\/** \n * Tell our token source and error strategy about a new way to create tokens. \n *\/\n","getRuleInvocationStack":"\/** \n * Return List&lt;String&gt; of the rule names in your parser instance leading up to a call to the current rule.  You could override if you want more details such as the file\/line info of where in the ATN a rule is invoked. This is very useful for error messages.\n *\/\n","setBuildParseTree":"\/** \n * Track the  {@link ParserRuleContext} objects during the parse and hookthem up using the  {@link ParserRuleContext#children} list so that itforms a parse tree. The  {@link ParserRuleContext} returned from the startrule represents the root of the parse tree. <p>Note that if we are not building parse trees, rule contexts only point upwards. When a rule exits, it returns the context but that gets garbage collected if nobody holds a reference. It points upwards but nobody points at it.<\/p> <p>When we build parse trees, we are adding all of these contexts to {@link ParserRuleContext#children} list. Contexts are then not candidatesfor garbage collection.<\/p>\n *\/\n","setProfile":"\/** \n * @since 4.3\n *\/\n","addParseListener":"\/** \n * Registers  {@code listener} to receive events during the parsing process.<p>To support output-preserving grammar transformations (including but not limited to left-recursion removal, automated left-factoring, and optimized code generation), calls to listener methods during the parse may differ substantially from calls made by {@link ParseTreeWalker#DEFAULT} used after the parse is complete. Inparticular, rule entry and exit events may occur in a different order during the parse than after the parser. In addition, calls to certain rule entry methods may be omitted.<\/p> <p>With the following specific exceptions, calls to listener events are <em>deterministic<\/em>, i.e. for identical input the calls to listener methods will be the same.<\/p> <ul> <li>Alterations to the grammar used to generate code may change the behavior of the listener calls.<\/li> <li>Alterations to the command line options passed to ANTLR 4 when generating the parser may change the behavior of the listener calls.<\/li> <li>Changing the version of the ANTLR Tool used to generate the parser may change the behavior of the listener calls.<\/li> <\/ul>\n * @param listener the listener to add\n * @throws NullPointerException if {@code} listener is {@code null}\n *\/\n","enterRule":"\/** \n * Always called by generated parsers upon entry to a rule. Access field {@link #_ctx} get the current context.\n *\/\n","enterRecursionRule":"\/** \n * @deprecated Use{@link #enterRecursionRule(ParserRuleContext,int,int,int)} instead.\n *\/\n","removeParseListener":"\/** \n * Remove  {@code listener} from the list of parse listeners.<p>If  {@code listener} is {@code null} or has not been added as a parselistener, this method does nothing.<\/p>\n * @see #addParseListener\n * @param listener the listener to remove\n *\/\n","reset":"\/** \n * reset the parser's state \n *\/\n","getDFAStrings":"\/** \n * For debugging and other purposes. \n *\/\n","isTrace":"\/** \n * Gets whether a  {@link TraceListener} is registered as a parse listenerfor the parser.\n * @see #setTrace(boolean)\n *\/\n","triggerEnterRuleEvent":"\/** \n * Notify any parse listeners of an enter rule event.\n * @see #addParseListener\n *\/\n","getNumberOfSyntaxErrors":"\/** \n * Gets the number of syntax errors reported during parsing. This value is incremented each time  {@link #notifyErrorListeners} is called.\n * @see #notifyErrorListeners\n *\/\n"}}
{"CodePointCharStream":{"getText":"\/** \n * Return the UTF-16 encoded string for the given interval \n *\/\n","fromBuffer":"\/** \n * Constructs a named  {@link CodePointCharStream} which provides accessto the Unicode code points stored in  {@code codePointBuffer}.\n *\/\n","mark":"\/** \n * mark\/release do nothing; we have entire buffer \n *\/\n"}}
{"ANTLRFileStream":{}}
{"ANTLRInputStream":{"reset":"\/** \n * Reset the stream so that it's in the same state it was when the object was created *except* the data array is not touched.\n *\/\n","index":"\/** \n * Return the current input symbol index 0..n where n indicates the last symbol has been read.  The index is the index of char to be returned from LA(1).\n *\/\n","seek":"\/** \n * consume() ahead until p==index; can't just set p=index as we must update line and charPositionInLine. If we seek backwards, just set p\n *\/\n","ANTLRInputStream":"\/** \n * This is the preferred constructor for strings as no data is copied \n *\/\n","mark":"\/** \n * mark\/release do nothing; we have entire buffer \n *\/\n"}}
{"RuntimeMetaData":{"getMajorMinorVersion":"\/** \n * Gets the major and minor version numbers from a version string. For details about the syntax of the input  {@code version}. E.g., from x.y.z return x.y.\n * @param version The complete version string.\n * @return A string of the form <em>major<\/em>.<em>minor<\/em> containingonly the major and minor components of the version string.\n *\/\n","checkVersion":"\/** \n * This method provides the ability to detect mismatches between the version of ANTLR 4 used to generate a parser, the version of the ANTLR runtime a parser was compiled against, and the version of the ANTLR runtime which is currently executing. <p> The version check is designed to detect the following two specific scenarios.<\/p> <ul> <li>The ANTLR Tool version used for code generation does not match the currently executing runtime version.<\/li> <li>The ANTLR Runtime version referenced at the time a parser was compiled does not match the currently executing runtime version.<\/li> <\/ul> <p> Starting with ANTLR 4.3, the code generator emits a call to this method using two constants in each generated lexer and parser: a hard-coded constant indicating the version of the tool used to generate the parser and a reference to the compile-time constant  {@link #VERSION}. At runtime, this method is called during the initialization of the generated parser to detect mismatched versions, and notify the registered listeners prior to creating instances of the parser.<\/p> <p> This method does not perform any detection or filtering of semantic changes between tool and runtime versions. It simply checks for a version match and emits an error to stderr if a difference is detected.<\/p> <p> Note that some breaking changes between releases could result in other types of runtime exceptions, such as a  {@link LinkageError}, prior to calling this method. In these cases, the underlying version mismatch will not be reported here. This method is primarily intended to notify users of potential semantic changes between releases that do not result in binary compatibility problems which would be detected by the class loader. As with semantic changes, changes that break binary compatibility between releases are mentioned in the release notes accompanying the affected release.<\/p> <p> <strong>Additional note for target developers:<\/strong> The version check implemented by this class is designed to address specific compatibility concerns that may arise during the execution of Java applications. Other targets should consider the implementation of this method in the context of that target's known execution environment, which may or may not resemble the design provided for the Java target.<\/p>\n * @param generatingToolVersion The version of the tool used to generate a parser.This value may be null when called from user code that was not generated by, and does not reference, the ANTLR 4 Tool itself.\n * @param compileTimeVersion The version of the runtime the parser wascompiled against. This should always be passed using a direct reference to  {@link #VERSION}.\n *\/\n","getRuntimeVersion":"\/** \n * Gets the currently executing version of the ANTLR 4 runtime library. <p> This method provides runtime access to the  {@link #VERSION} field, asopposed to directly referencing the field as a compile-time constant.<\/p>\n * @return The currently executing version of the ANTLR 4 library\n *\/\n"}}
{"DFA":{"setPrecedenceDfa":"\/** \n * Sets whether this is a precedence DFA.\n * @param precedenceDfa {@code true} if this is a precedence DFA; otherwise,{@code false}\n * @throws UnsupportedOperationException if {@code precedenceDfa} does notmatch the value of  {@link #isPrecedenceDfa} for the current DFA.\n * @deprecated This method no longer performs any action.\n *\/\n","getPrecedenceStartState":"\/** \n * Get the start state for a specific precedence value.\n * @param precedence The current precedence.\n * @return The start state corresponding to the specified precedence, or{@code null} if no start state exists for the specified precedence.\n * @throws IllegalStateException if this is not a precedence DFA.\n * @see #isPrecedenceDfa()\n *\/\n","setPrecedenceStartState":"\/** \n * Set the start state for a specific precedence value.\n * @param precedence The current precedence.\n * @param startState The start state corresponding to the specifiedprecedence.\n * @throws IllegalStateException if this is not a precedence DFA.\n * @see #isPrecedenceDfa()\n *\/\n","toString":"\/** \n * @deprecated Use {@link #toString(Vocabulary)} instead.\n *\/\n","isPrecedenceDfa":"\/** \n * Gets whether this DFA is a precedence DFA. Precedence DFAs use a special start state  {@link #s0} which is not stored in {@link #states}. The {@link DFAState#edges} array for this start state contains outgoing edgessupplying individual start states corresponding to specific precedence values.\n * @return {@code true} if this is a precedence DFA; otherwise,{@code false}.\n * @see Parser#getPrecedence()\n *\/\n","getStates":"\/** \n * Return a list of all states in this DFA, ordered by state number.\n *\/\n"}}
{"DFAState":{"equals":"\/** \n * Two  {@link DFAState} instances are equal if their ATN configuration setsare the same. This method is used to see if a state already exists. <p>Because the number of alternatives and number of ATN configurations are finite, there is a finite number of DFA states that can be processed. This is necessary to show that the algorithm terminates.<\/p> <p>Cannot test the DFA state numbers here because in {@link ParserATNSimulator#addDFAState} we need to know if any other stateexists that has this exact set of ATN configurations. The {@link #stateNumber} is irrelevant.<\/p>\n *\/\n","getAltSet":"\/** \n * Get the set of all alts mentioned by all ATN configurations in this DFA state.\n *\/\n"}}
{"DFASerializer":{"DFASerializer":"\/** \n * @deprecated Use {@link #DFASerializer(DFA,Vocabulary)} instead.\n *\/\n"}}
{"LexerDFASerializer":{}}
{"InputMismatchException":{}}
{"UnbufferedCharStream":{"release":"\/** \n * Decrement number of markers, resetting buffer if we hit 0.\n * @param marker\n *\/\n","nextChar":"\/** \n * Override to provide different source of characters than {@link #input input}.\n *\/\n","UnbufferedCharStream":"\/** \n * Useful for subclasses that pull char from other than this.input. \n *\/\n","fill":"\/** \n * Add  {@code n} characters to the buffer. Returns the number of charactersactually added to the buffer. If the return value is less than  {@code n}, then EOF was reached before  {@code n} characters could be added.\n *\/\n","sync":"\/** \n * Make sure we have 'need' elements from current position  {@link #p p}. Last valid  {@code p} index is {@code data.length-1}.  {@code p+need-1} isthe char index 'need' elements ahead. If we need 1 element, {@code (p+1-1)==p} must be less than {@code data.length}.\n *\/\n","seek":"\/** \n * Seek to absolute character index, which might not be in the current sliding window.  Move  {@code p} to {@code index-bufferStartIndex}.\n *\/\n","mark":"\/** \n * Return a marker that we can release later. <p>The specific marker value used for this class allows for some level of protection against misuse where  {@code seek()} is called on a mark or{@code release()} is called in the wrong order.<\/p>\n *\/\n"}}
{"CommonTokenFactory":{"CommonTokenFactory":"\/** \n * Constructs a  {@link CommonTokenFactory} with {@link #copyText} set to{@code false}. <p> The  {@link #DEFAULT} instance should be used instead of calling thisdirectly.<\/p>\n *\/\n"}}
{"CodePointBuffer":{}}
{"LexerInterpreter":{}}
{"BufferedTokenStream":{"getText":"\/** \n * Get the text of all tokens in this buffer. \n *\/\n","getTokens":"\/** \n * Given a start and stop index, return a List of all tokens in the token type BitSet.  Return null if no tokens were found.  This method looks at both on and off channel tokens.\n *\/\n","getHiddenTokensToLeft":"\/** \n * Collect all hidden tokens (any off-default channel) to the left of the current token up until we see a token on DEFAULT_TOKEN_CHANNEL.\n *\/\n","fill":"\/** \n * Get all tokens from lexer until EOF \n *\/\n","sync":"\/** \n * Make sure index  {@code i} in tokens has a token.\n * @return {@code true} if a token is located at index {@code i}, otherwise {@code false}.\n * @see #get(int i)\n *\/\n","adjustSeekIndex":"\/** \n * Allowed derived classes to modify the behavior of operations which change the current stream position by adjusting the target token index of a seek operation. The default implementation simply returns  {@code i}. If an exception is thrown in this method, the current stream index should not be changed. <p>For example,  {@link CommonTokenStream} overrides this method to ensure thatthe seek target is always an on-channel token.<\/p>\n * @param i The target token index.\n * @return The adjusted target token index.\n *\/\n","fetch":"\/** \n * Add  {@code n} elements to buffer.\n * @return The actual number of elements added to the buffer.\n *\/\n","get":"\/** \n * Get all tokens from start..stop inclusively \n *\/\n","reset":"\/** \n * This method resets the token stream back to the first token in the buffer. It is equivalent to calling  {@link #seek}{@code (0)}.\n * @see #setTokenSource(TokenSource)\n * @deprecated Use {@code seek(0)} instead.\n *\/\n","getHiddenTokensToRight":"\/** \n * Collect all hidden tokens (any off-default channel) to the right of the current token up until we see a token on DEFAULT_TOKEN_CHANNEL or EOF.\n *\/\n","setTokenSource":"\/** \n * Reset this token stream by setting its token source. \n *\/\n","nextTokenOnChannel":"\/** \n * Given a starting index, return the index of the next token on channel. Return  {@code i} if {@code tokens[i]} is on channel. Return the index ofthe EOF token if there are no tokens on channel between  {@code i} andEOF.\n *\/\n","previousTokenOnChannel":"\/** \n * Given a starting index, return the index of the previous token on channel. Return  {@code i} if {@code tokens[i]} is on channel. Return -1if there are no tokens on channel between  {@code i} and 0.<p> If  {@code i} specifies an index at or after the EOF token, the EOF tokenindex is returned. This is due to the fact that the EOF token is treated as though it were on every channel.<\/p>\n *\/\n"}}
{"CharStream":{"getText":"\/** \n * This method returns the text for a range of characters within this input stream. This method is guaranteed to not throw an exception if the specified  {@code interval} lies entirely within a marked range. For moreinformation about marked ranges, see  {@link IntStream#mark}.\n * @param interval an interval within the stream\n * @return the text of the specified interval\n * @throws NullPointerException if {@code interval} is {@code null}\n * @throws IllegalArgumentException if {@code interval.a < 0}, or if {@code interval.b < interval.a - 1}, or if  {@code interval.b} lies at orpast the end of the stream\n * @throws UnsupportedOperationException if the stream does not supportgetting the text of the specified interval\n *\/\n"}}
{"TokenStream":{"getText":"\/** \n * Return the text of all tokens in this stream between  {@code start} and{@code stop} (inclusive).<p>If the specified  {@code start} or {@code stop} token was not provided bythis stream, or if the  {@code stop} occurred before the {@code start}token, the behavior is unspecified.<\/p> <p>For streams which ensure that the  {@link Token#getTokenIndex} method isaccurate for all of its provided tokens, this method behaves like the following code. Other streams may implement this method in other ways provided the behavior is consistent with this at a high level.<\/p> <pre> TokenStream stream = ...; String text = \"\"; for (int i = start.getTokenIndex(); i &lt;= stop.getTokenIndex(); i++) { text += stream.get(i).getText(); } <\/pre>\n * @param start The first token in the interval to get text for.\n * @param stop The last token in the interval to get text for (inclusive).\n * @return The text of all tokens lying between the specified {@code start}and  {@code stop} tokens.\n * @throws UnsupportedOperationException if this stream does not supportthis method for the specified tokens\n *\/\n","get":"\/** \n * Gets the  {@link Token} at the specified {@code index} in the stream. Whenthe preconditions of this method are met, the return value is non-null. <p>The preconditions for this method are the same as the preconditions of {@link IntStream#seek}. If the behavior of  {@code seek(index)} isunspecified for the current state and given  {@code index}, then the behavior of this method is also unspecified.<\/p> <p>The symbol referred to by  {@code index} differs from {@code seek()} onlyin the case of filtering streams where  {@code index} lies before the endof the stream. Unlike  {@code seek()}, this method does not adjust {@code index} to point to a non-ignored symbol.<\/p>\n * @throws IllegalArgumentException if {code index} is less than 0\n * @throws UnsupportedOperationException if the stream does not supportretrieving the token at the specified index\n *\/\n","LT":"\/** \n * Get the  {@link Token} instance associated with the value returned by{@link #LA LA(k)}. This method has the same pre- and post-conditions as {@link IntStream#LA}. In addition, when the preconditions of this method are met, the return value is non-null and the value of {@code LT(k).getType()==LA(k)}.\n * @see IntStream#LA\n *\/\n","getTokenSource":"\/** \n * Gets the underlying  {@link TokenSource} which provides tokens for thisstream.\n *\/\n"}}
{"TokenStreamRewriter":{"rollback":"\/** \n * Rollback the instruction stream for a program so that the indicated instruction (via instructionIndex) is no longer in the stream. UNTESTED!\n *\/\n","deleteProgram":"\/** \n * Reset the program so that no instructions exist \n *\/\n","getText":"\/** \n * Return the text associated with the tokens in the interval from the original token stream but with the alterations given to this rewriter. The interval refers to the indexes in the original token stream. We do not alter the token stream in any way, so the indexes and intervals are still consistent. Includes any operations done to the first and last token in the interval. So, if you did an insertBefore on the first token, you would get that insertion. The same is true if you do an insertAfter the stop token.\n *\/\n","reduceToSingleOperationPerIndex":"\/** \n * We need to combine operations and report invalid operations (like overlapping replaces that are not completed nested). Inserts to same index need to be combined etc...  Here are the cases: I.i.u I.j.v\t\t\t\t\t\t\t\tleave alone, nonoverlapping I.i.u I.i.v\t\t\t\t\t\t\t\tcombine: Iivu R.i-j.u R.x-y.v\t| i-j in x-y\t\t\tdelete first R R.i-j.u R.i-j.v\t\t\t\t\t\t\tdelete first R R.i-j.u R.x-y.v\t| x-y in i-j\t\t\tERROR R.i-j.u R.x-y.v\t| boundaries overlap\tERROR Delete special case of replace (text==null): D.i-j.u D.x-y.v\t| boundaries overlap\tcombine to max(min)..max(right) I.i.u R.x-y.v | i in (x+1)-y\t\t\tdelete I (since insert before we're not deleting i) I.i.u R.x-y.v | i not in (x+1)-y\t\tleave alone, nonoverlapping R.x-y.v I.i.u | i in x-y\t\t\t\tERROR R.x-y.v I.x.u \t\t\t\t\t\t\tR.x-y.uv (combine, delete I) R.x-y.v I.i.u | i not in x-y\t\t\tleave alone, nonoverlapping I.i.u = insert u before op @ index i R.x-y.u = replace x-y indexed tokens with u First we need to examine replaces. For any replace op: 1. wipe out any insertions before op within that range. 2. Drop any replace op before that is contained completely within that range. 3. Throw exception upon boundary overlap with any previous replace. Then we can deal with inserts: 1. for any inserts to same index, combine even if not adjacent. 2. for any prior replace with same left boundary, combine this insert with replace and delete this replace. 3. throw exception if index in same range as previous replace Don't actually delete; make op null in list. Easier to walk list. Later we can throw as we add to index &rarr; op map. Note that I.2 R.2-2 will wipe out I.2 even though, technically, the inserted stuff would be before the replace range. But, if you add tokens in front of a method body '{' and then delete the method body, I think the stuff before the '{' you added should disappear too. Return a map from token index to operation.\n *\/\n","execute":"\/** \n * Execute the rewrite operation by possibly adding to the buffer. Return the index of the next token to operate on.\n *\/\n","getKindOfOps":"\/** \n * Get all operations before an index of a particular kind \n *\/\n"}}
{"ListTokenSource":{"getSourceName":"\/** \n * {@inheritDoc}\n *\/\n","getTokenFactory":"\/** \n * {@inheritDoc}\n *\/\n","nextToken":"\/** \n * {@inheritDoc}\n *\/\n","getCharPositionInLine":"\/** \n * {@inheritDoc}\n *\/\n","getLine":"\/** \n * {@inheritDoc}\n *\/\n","setTokenFactory":"\/** \n * {@inheritDoc}\n *\/\n","ListTokenSource":"\/** \n * Constructs a new  {@link ListTokenSource} instance from the specifiedcollection of  {@link Token} objects and source name.\n * @param tokens The collection of {@link Token} objects to provide as a{@link TokenSource}.\n * @param sourceName The name of the {@link TokenSource}. If this value is {@code null},  {@link #getSourceName} will attempt to infer the name fromthe next  {@link Token} (or the previous token if the end of the input hasbeen reached).\n * @exception NullPointerException if {@code tokens} is {@code null}\n *\/\n","getInputStream":"\/** \n * {@inheritDoc}\n *\/\n"}}
{"WritableToken":{}}
{"ANTLRErrorListener":{"reportContextSensitivity":"\/** \n * This method is called by the parser when a full-context prediction has a unique result. <p>Each full-context prediction which does not result in a syntax error will call either  {@link #reportContextSensitivity} or{@link #reportAmbiguity}.<\/p> <p>For prediction implementations that only evaluate full-context predictions when an SLL conflict is found (including the default {@link ParserATNSimulator} implementation), this method reports caseswhere SLL conflicts were resolved to unique full-context predictions, i.e. the decision was context-sensitive. This report does not necessarily indicate a problem, and it may appear even in completely unambiguous grammars.<\/p> <p> {@code configs} may have more than one represented alternative if thefull-context prediction algorithm does not evaluate predicates before beginning the full-context prediction. In all cases, the final prediction is passed as the  {@code prediction} argument.<\/p><p>Note that the definition of \"context sensitivity\" in this method differs from the concept in  {@link DecisionInfo#contextSensitivities}. This method reports all instances where an SLL conflict occurred but LL parsing produced a unique result, whether or not that unique result matches the minimum alternative in the SLL conflicting set.<\/p> <p>This method is not used by lexers.<\/p>\n * @param recognizer the parser instance\n * @param dfa the DFA for the current decision\n * @param startIndex the input index where the decision started\n * @param stopIndex the input index where the context sensitivity wasfinally determined\n * @param prediction the unambiguous result of the full-context prediction\n * @param configs the ATN configuration set where the unambiguous predictionwas determined\n *\/\n","syntaxError":"\/** \n * Upon syntax error, notify any interested parties. This is not how to recover from errors or compute error messages.  {@link ANTLRErrorStrategy}specifies how to recover from syntax errors and how to compute error messages. This listener's job is simply to emit a computed message, though it has enough information to create its own message in many cases. <p>The  {@link RecognitionException} is non-null for all syntax errors exceptwhen we discover mismatched token errors that we can recover from in-line, without returning from the surrounding rule (via the single token insertion and deletion mechanism).<\/p>\n * @param recognizer What parser got the error. From this object, you can access the context as well as the input stream.\n * @param offendingSymbol The offending token in the input token stream, unless recognizer is a lexer (then it's null). If no viable alternative error,  {@code e} has token at which westarted production for the decision.\n * @param line The line number in the input where the error occurred.\n * @param charPositionInLine The character position within that line where the error occurred.\n * @param msg The message to emit.\n * @param e The exception generated by the parser that led to the reporting of an error. It is null in the case where the parser was able to recover in line without exiting the surrounding rule.\n *\/\n","reportAmbiguity":"\/** \n * This method is called by the parser when a full-context prediction results in an ambiguity. <p>Each full-context prediction which does not result in a syntax error will call either  {@link #reportContextSensitivity} or{@link #reportAmbiguity}.<\/p> <p>When  {@code ambigAlts} is not null, it contains the set of potentiallyviable alternatives identified by the prediction algorithm. When {@code ambigAlts} is null, use {@link ATNConfigSet#getAlts} to obtain therepresented alternatives from the  {@code configs} argument.<\/p><p>When  {@code exact} is {@code true}, <em>all<\/em> of the potentially viable alternatives are truly viable, i.e. this is reporting an exact ambiguity. When  {@code exact} is {@code false}, <em>at least two<\/em> of the potentially viable alternatives are viable for the current input, but the prediction algorithm terminated as soon as it determined that at least the <em>minimum<\/em> potentially viable alternative is truly viable.<\/p> <p>When the  {@link PredictionMode#LL_EXACT_AMBIG_DETECTION} predictionmode is used, the parser is required to identify exact ambiguities so {@code exact} will always be {@code true}.<\/p> <p>This method is not used by lexers.<\/p>\n * @param recognizer the parser instance\n * @param dfa the DFA for the current decision\n * @param startIndex the input index where the decision started\n * @param stopIndex the input input where the ambiguity was identified\n * @param exact {@code true} if the ambiguity is exactly known, otherwise{@code false}. This is always  {@code true} when{@link PredictionMode#LL_EXACT_AMBIG_DETECTION} is used.\n * @param ambigAlts the potentially ambiguous alternatives, or {@code null}to indicate that the potentially ambiguous alternatives are the complete set of represented alternatives in  {@code configs}\n * @param configs the ATN configuration set where the ambiguity wasidentified\n *\/\n","reportAttemptingFullContext":"\/** \n * This method is called when an SLL conflict occurs and the parser is about to use the full context information to make an LL decision. <p>If one or more configurations in  {@code configs} contains a semanticpredicate, the predicates are evaluated before this method is called. The subset of alternatives which are still viable after predicates are evaluated is reported in  {@code conflictingAlts}.<\/p> <p>This method is not used by lexers.<\/p>\n * @param recognizer the parser instance\n * @param dfa the DFA for the current decision\n * @param startIndex the input index where the decision started\n * @param stopIndex the input index where the SLL conflict occurred\n * @param conflictingAlts The specific conflicting alternatives. If this is{@code null}, the conflicting alternatives are all alternatives represented in  {@code configs}. At the moment, conflictingAlts is non-null (for the reference implementation, but Sam's optimized version can see this as null).\n * @param configs the ATN configuration set where the SLL conflict wasdetected\n *\/\n"}}
{"IntStream":{"getSourceName":"\/** \n * Gets the name of the underlying symbol source. This method returns a non-null, non-empty string. If such a name is not known, this method returns  {@link #UNKNOWN_SOURCE_NAME}.\n *\/\n","size":"\/** \n * Returns the total number of symbols in the stream, including a single EOF symbol.\n * @throws UnsupportedOperationException if the size of the stream isunknown.\n *\/\n","LA":"\/** \n * Gets the value of the symbol at offset  {@code i} from the currentposition. When  {@code i==1}, this method returns the value of the current symbol in the stream (which is the next symbol to be consumed). When {@code i==-1}, this method returns the value of the previously read symbol in the stream. It is not valid to call this method with {@code i==0}, but the specific behavior is unspecified because this method is frequently called from performance-critical code. <p>This method is guaranteed to succeed if any of the following are true:<\/p> <ul> <li> {@code i>0}<\/li> <li> {@code i==-1} and {@link #index index()} returns a value greaterthan the value of  {@code index()} after the stream was constructedand  {@code LA(1)} was called in that order. Specifying the current{@code index()} relative to the index after the stream was createdallows for filtering implementations that do not return every symbol from the underlying source. Specifying the call to  {@code LA(1)}allows for lazily initialized streams.<\/li> <li> {@code LA(i)} refers to a symbol consumed within a marked regionthat has not yet been released.<\/li> <\/ul> <p>If  {@code i} represents a position at or beyond the end of the stream,this method returns  {@link #EOF}.<\/p> <p>The return value is unspecified if  {@code i<0} and fewer than {@code -i}calls to  {@link #consume consume()} have occurred from the beginning ofthe stream before calling this method.<\/p>\n * @throws UnsupportedOperationException if the stream does not supportretrieving the value of the specified symbol\n *\/\n","release":"\/** \n * This method releases a marked range created by a call to {@link #mark mark()}. Calls to  {@code release()} must appear in thereverse order of the corresponding calls to  {@code mark()}. If a mark is released twice, or if marks are not released in reverse order of the corresponding calls to  {@code mark()}, the behavior is unspecified. <p>For more information and an example, see  {@link #mark}.<\/p>\n * @param marker A marker returned by a call to {@code mark()}.\n * @see #mark\n *\/\n","index":"\/** \n * Return the index into the stream of the input symbol referred to by {@code LA(1)}. <p>The behavior of this method is unspecified if no call to an {@link IntStream initializing method} has occurred after this stream wasconstructed.<\/p>\n *\/\n","consume":"\/** \n * Consumes the current symbol in the stream. This method has the following effects: <ul> <li><strong>Forward movement:<\/strong> The value of  {@link #index index()}before calling this method is less than the value of  {@code index()}after calling this method.<\/li> <li><strong>Ordered lookahead:<\/strong> The value of  {@code LA(1)} beforecalling this method becomes the value of  {@code LA(-1)} after callingthis method.<\/li> <\/ul> Note that calling this method does not guarantee that  {@code index()} isincremented by exactly 1, as that would preclude the ability to implement filtering streams (e.g.  {@link CommonTokenStream} which distinguishesbetween \"on-channel\" and \"off-channel\" tokens).\n * @throws IllegalStateException if an attempt is made to consume theend of the stream (i.e. if  {@code LA(1)==}{@link #EOF EOF} before calling{@code consume}).\n *\/\n","seek":"\/** \n * Set the input cursor to the position indicated by  {@code index}. If the specified index lies past the end of the stream, the operation behaves as though  {@code index} was the index of the EOF symbol. After this methodreturns without throwing an exception, then at least one of the following will be true. <ul> <li> {@link #index index()} will return the index of the first symbolappearing at or after the specified  {@code index}. Specifically, implementations which filter their sources should automatically adjust  {@code index} forward the minimum amount required for theoperation to target a non-ignored symbol.<\/li> <li> {@code LA(1)} returns {@link #EOF}<\/li> <\/ul> This operation is guaranteed to not throw an exception if  {@code index}lies within a marked region. For more information on marked regions, see {@link #mark}. The behavior of this method is unspecified if no call to an  {@link IntStream initializing method} has occurred after this streamwas constructed.\n * @param index The absolute index to seek to.\n * @throws IllegalArgumentException if {@code index} is less than 0\n * @throws UnsupportedOperationException if the stream does not supportseeking to the specified index\n *\/\n","mark":"\/** \n * A mark provides a guarantee that  {@link #seek seek()} operations will bevalid over a \"marked range\" extending from the index where  {@code mark()}was called to the current  {@link #index index()}. This allows the use of streaming input sources by specifying the minimum buffering requirements to support arbitrary lookahead during prediction. <p>The returned mark is an opaque handle (type  {@code int}) which is passed to  {@link #release release()} when the guarantees provided by the markedrange are no longer necessary. When calls to {@code mark()}\/ {@code release()} are nested, the marks must be releasedin reverse order of which they were obtained. Since marked regions are used during performance-critical sections of prediction, the specific behavior of invalid usage is unspecified (i.e. a mark is not released, or a mark is released twice, or marks are not released in reverse order from which they were created).<\/p> <p>The behavior of this method is unspecified if no call to an {@link IntStream initializing method} has occurred after this stream wasconstructed.<\/p> <p>This method does not change the current position in the input stream.<\/p> <p>The following example shows the use of  {@link #mark mark()}, {@link #release release(mark)},  {@link #index index()}, and {@link #seek seek(index)} as part of an operation to safely work within amarked region, then restore the stream position to its original value and release the mark.<\/p> <pre> IntStream stream = ...; int index = -1; int mark = stream.mark(); try { index = stream.index(); \/\/ perform work here... } finally { if (index != -1) { stream.seek(index); } stream.release(mark); } <\/pre>\n * @return An opaque marker which should be passed to{@link #release release()} when the marked range is no longer required.\n *\/\n"}}
{"RuleContextWithAltNum":{}}
{"CharStreams":{"fromPath":"\/** \n * Creates a  {@link CharStream} given a path to a file on disk and thecharset of the bytes contained in the file. Reads the entire contents of the file into the result before returning.\n *\/\n","fromStream":"\/** \n * Creates a  {@link CharStream} given an opened {@link InputStream} and thecharset of the bytes contained in the stream. Reads the entire contents of the  {@code InputStream} intothe result before returning, then closes the  {@code InputStream}.\n *\/\n","fromChannel":"\/** \n * Creates a  {@link CharStream} given an opened {@link ReadableByteChannel}containing UTF-8 bytes. Reads the entire contents of the  {@code channel} intothe result before returning, then closes the  {@code channel}.\n *\/\n","fromFileName":"\/** \n * Creates a  {@link CharStream} given a string containing apath to a file on disk and the charset of the bytes contained in the file. Reads the entire contents of the file into the result before returning.\n *\/\n","fromString":"\/** \n * Creates a  {@link CharStream} given a {@link String} and the {@code sourceName}from which it came.\n *\/\n","fromReader":"\/** \n * Creates a  {@link CharStream} given a {@link Reader} and itssource name. Closes the reader before returning.\n *\/\n"}}
{"FailedPredicateException":{}}
{"Recognizer":{"getRuleIndexMap":"\/** \n * Get a map from rule names to rule indexes. <p>Used for XPath and tree pattern compilation.<\/p>\n *\/\n","getInterpreter":"\/** \n * Get the ATN interpreter used by the recognizer for prediction.\n * @return The ATN interpreter used by the recognizer for prediction.\n *\/\n","getVocabulary":"\/** \n * Get the vocabulary used by the recognizer.\n * @return A {@link Vocabulary} instance providing information about thevocabulary used by the grammar.\n *\/\n","getATN":"\/** \n * Get the  {@link ATN} used by the recognizer for prediction.\n * @return The {@link ATN} used by the recognizer for prediction.\n *\/\n","getParseInfo":"\/** \n * If profiling during the parse\/lex, this will return DecisionInfo records for each decision in recognizer in a ParseInfo object.\n * @since 4.3\n *\/\n","getTokenNames":"\/** \n * Used to print out token names like ID during debugging and error reporting.  The generated parsers implement a method that overrides this to point to their String[] tokenNames.\n * @deprecated Use {@link #getVocabulary()} instead.\n *\/\n","getSerializedATN":"\/** \n * If this recognizer was generated, it will have a serialized ATN representation of the grammar. <p>For interpreters, we don't know their serialized ATN despite having created the interpreter from it.<\/p>\n *\/\n","getTokenErrorDisplay":"\/** \n * How should a token be displayed in an error message? The default is to display just the text, but during development you might want to have a lot of information spit out.  Override in that case to use t.toString() (which, for CommonToken, dumps everything about the token). This is better than forcing you to override a method in your token objects because you don't have to go modify your lexer so that it creates a new Java type.\n * @deprecated This method is not called by the ANTLR 4 Runtime. Specificimplementations of  {@link ANTLRErrorStrategy} may provide a similarfeature when necessary. For example, see {@link DefaultErrorStrategy#getTokenErrorDisplay}.\n *\/\n","getTokenTypeMap":"\/** \n * Get a map from token names to token types. <p>Used for XPath and tree pattern compilation.<\/p>\n *\/\n","addErrorListener":"\/** \n * @exception NullPointerException if {@code listener} is {@code null}.\n *\/\n","setInterpreter":"\/** \n * Set the ATN interpreter used by the recognizer for prediction.\n * @param interpreter The ATN interpreter used by the recognizer forprediction.\n *\/\n","setState":"\/** \n * Indicate that the recognizer has changed internal state that is consistent with the ATN state passed in.  This way we always know where we are in the ATN as the parser goes along. The rule context objects form a stack that lets us see the stack of invoking rules. Combine this and we have complete ATN configuration information.\n *\/\n","getGrammarFileName":"\/** \n * For debugging and other purposes, might want the grammar name. Have ANTLR generate an implementation for this method.\n *\/\n","getErrorHeader":"\/** \n * What is the error header, normally line\/character position information? \n *\/\n"}}
{"ParserInterpreter":{"ParserInterpreter":"\/** \n * @deprecated Use {@link #ParserInterpreter(String,Vocabulary,Collection,ATN,TokenStream)} instead.\n *\/\n","recover":"\/** \n * Rely on the error handler for this parser but, if no tokens are consumed to recover, add an error node. Otherwise, nothing is seen in the parse tree.\n *\/\n","visitDecisionState":"\/** \n * Method visitDecisionState() is called when the interpreter reaches a decision state (instance of DecisionState). It gives an opportunity for subclasses to track interesting things.\n *\/\n","parse":"\/** \n * Begin parsing at startRuleIndex \n *\/\n","addDecisionOverride":"\/** \n * Override this parser interpreters normal decision-making process at a particular decision and input token index. Instead of allowing the adaptive prediction mechanism to choose the first alternative within a block that leads to a successful parse, force it to take the alternative, 1..n for n alternatives. As an implementation limitation right now, you can only specify one override. This is sufficient to allow construction of different parse trees for ambiguous input. It means re-parsing the entire input in general because you're never sure where an ambiguous sequence would live in the various parse trees. For example, in one interpretation, an ambiguous input sequence would be matched completely in expression but in another it could match all the way back to the root. s : e '!'? ; e : ID | ID '!' ; Here, x! can be matched as (s (e ID) !) or (s (e ID !)). In the first case, the ambiguous sequence is fully contained only by the root. In the second case, the ambiguous sequences fully contained within just e, as in: (e ID !). Rather than trying to optimize this and make some intelligent decisions for optimization purposes, I settled on just re-parsing the whole input and then using {link Trees#getRootOfSubtreeEnclosingRegion} to find the minimal subtree that contains the ambiguous sequence. I originally tried to record the call stack at the point the parser detected and ambiguity but left recursive rules create a parse tree stack that does not reflect the actual call stack. That impedance mismatch was enough to make it it challenging to restart the parser at a deeply nested rule invocation. Only parser interpreters can override decisions so as to avoid inserting override checking code in the critical ALL(*) prediction execution path.\n * @since 4.5.1\n *\/\n","getRootContext":"\/** \n * Return the root of the parse, which can be useful if the parser bails out. You still can access the top node. Note that, because of the way left recursive rules add children, it's possible that the root will not have any children if the start rule immediately called and left recursive rule that fails.\n * @since 4.5.1\n *\/\n","createInterpreterRuleContext":"\/** \n * Provide simple \"factory\" for InterpreterRuleContext's.\n * @since 4.5.1\n *\/\n"}}
{"UnbufferedTokenStream":{"fill":"\/** \n * Add  {@code n} elements to the buffer. Returns the number of tokensactually added to the buffer. If the return value is less than  {@code n}, then EOF was reached before  {@code n} tokens could be added.\n *\/\n","sync":"\/** \n * Make sure we have 'need' elements from current position  {@link #p p}. Last valid {@code p} index is {@code tokens.length-1}.   {@code p+need-1} is the tokens index 'need' elementsahead.  If we need 1 element,  {@code (p+1-1)==p} must be less than {@code tokens.length}.\n *\/\n","mark":"\/** \n * Return a marker that we can release later. <p>The specific marker value used for this class allows for some level of protection against misuse where  {@code seek()} is called on a mark or{@code release()} is called in the wrong order.<\/p>\n *\/\n"}}
{"VocabularyImpl":{"VocabularyImpl":"\/** \n * Constructs a new instance of  {@link VocabularyImpl} from the specifiedliteral, symbolic, and display token names.\n * @param literalNames The literal names assigned to tokens, or {@code null}if no literal names are assigned.\n * @param symbolicNames The symbolic names assigned to tokens, or{@code null} if no symbolic names are assigned.\n * @param displayNames The display names assigned to tokens, or {@code null}to use the values in  {@code literalNames} and {@code symbolicNames} asthe source of display names, as described in {@link #getDisplayName(int)}.\n * @see #getLiteralName(int)\n * @see #getSymbolicName(int)\n * @see #getDisplayName(int)\n *\/\n","fromTokenNames":"\/** \n * Returns a  {@link VocabularyImpl} instance from the specified set of tokennames. This method acts as a compatibility layer for the single {@code tokenNames} array generated by previous releases of ANTLR.<p>The resulting vocabulary instance returns  {@code null} for{@link #getLiteralName(int)} and {@link #getSymbolicName(int)}, and the value from  {@code tokenNames} for the display names.<\/p>\n * @param tokenNames The token names, or {@code null} if no token names areavailable.\n * @return A {@link Vocabulary} instance which uses {@code tokenNames} forthe display names of tokens.\n *\/\n"}}
{"LexerNoViableAltException":{}}
{"Lexer":{"getTokenNames":"\/** \n * Used to print out token names like ID during debugging and error reporting.  The generated parsers implement a method that overrides this to point to their String[] tokenNames.\n *\/\n","recover":"\/** \n * Lexers can normally match any char in it's vocabulary after matching a token, so do the easy thing and just kill a character and hope it all works out.  You can instead use the rule invocation stack to do sophisticated error recovery if you are in a fragment rule.\n *\/\n","getAllTokens":"\/** \n * Return a list of all Token objects in input char stream. Forces load of all tokens. Does not include EOF token.\n *\/\n","nextToken":"\/** \n * Return a token from this source; i.e., match a token on the char stream.\n *\/\n","setInputStream":"\/** \n * Set the char stream and reset the lexer \n *\/\n","getText":"\/** \n * Return the text matched so far for the current token or any text override.\n *\/\n","getToken":"\/** \n * Override if emitting multiple tokens. \n *\/\n","skip":"\/** \n * Instruct the lexer to skip creating a token for current lexer rule and look for another token.  nextToken() knows to keep looking when a lexer rule finishes with token set to SKIP_TOKEN.  Recall that if token==null at end of any token rule, it creates one for you and emits it.\n *\/\n","emit":"\/** \n * The standard method called to automatically emit a token at the outermost lexical rule.  The token object should point into the char buffer start..stop.  If there is a text override in 'text', use that to set the token's text.  Override this method to emit custom Token objects or provide a new factory.\n *\/\n","getCharIndex":"\/** \n * What is the index of the current character of lookahead? \n *\/\n","setText":"\/** \n * Set the complete text of this token; it wipes any previous changes to the text.\n *\/\n"}}
{"ConsoleErrorListener":{"syntaxError":"\/** \n * {@inheritDoc}<p> This implementation prints messages to  {@link System#err} containing thevalues of  {@code line},  {@code charPositionInLine}, and  {@code msg} usingthe following format.<\/p> <pre> line <em>line<\/em>:<em>charPositionInLine<\/em> <em>msg<\/em> <\/pre>\n *\/\n"}}
{"ANTLRErrorStrategy":{"recover":"\/** \n * This method is called to recover from exception  {@code e}. This method is called after  {@link #reportError} by the default exception handlergenerated for a rule method.\n * @see #reportError\n * @param recognizer the parser instance\n * @param e the recognition exception to recover from\n * @throws RecognitionException if the error strategy could not recover fromthe recognition exception\n *\/\n","reportMatch":"\/** \n * This method is called by when the parser successfully matches an input symbol.\n * @param recognizer the parser instance\n *\/\n","reset":"\/** \n * Reset the error handler state for the specified  {@code recognizer}.\n * @param recognizer the parser instance\n *\/\n","inErrorRecoveryMode":"\/** \n * Tests whether or not  {@code recognizer} is in the process of recoveringfrom an error. In error recovery mode,  {@link Parser#consume} addssymbols to the parse tree by calling {@link Parser#createErrorNode(ParserRuleContext,Token)} then{@link ParserRuleContext#addErrorNode(ErrorNode)} instead of{@link Parser#createTerminalNode(ParserRuleContext,Token)}.\n * @param recognizer the parser instance\n * @return {@code true} if the parser is currently recovering from a parseerror, otherwise  {@code false}\n *\/\n","reportError":"\/** \n * Report any kind of  {@link RecognitionException}. This method is called by the default exception handler generated for a rule method.\n * @param recognizer the parser instance\n * @param e the recognition exception to report\n *\/\n","sync":"\/** \n * This method provides the error handler with an opportunity to handle syntactic or semantic errors in the input stream before they result in a {@link RecognitionException}. <p>The generated code currently contains calls to  {@link #sync} afterentering the decision state of a closure block ( {@code (...)*} or{@code (...)+}).<\/p> <p>For an implementation based on Jim Idle's \"magic sync\" mechanism, see {@link DefaultErrorStrategy#sync}.<\/p>\n * @see DefaultErrorStrategy#sync\n * @param recognizer the parser instance\n * @throws RecognitionException if an error is detected by the errorstrategy but cannot be automatically recovered at the current state in the parsing process\n *\/\n","recoverInline":"\/** \n * This method is called when an unexpected symbol is encountered during an inline match operation, such as  {@link Parser#match}. If the error strategy successfully recovers from the match failure, this method returns the  {@link Token} instance which should be treated as thesuccessful result of the match. <p>This method handles the consumption of any tokens - the caller should <b>not<\/b> call  {@link Parser#consume} after a successful recovery.<\/p><p>Note that the calling code will not report an error if this method returns successfully. The error strategy implementation is responsible for calling  {@link Parser#notifyErrorListeners} as appropriate.<\/p>\n * @param recognizer the parser instance\n * @throws RecognitionException if the error strategy was not able torecover from the unexpected input symbol\n *\/\n"}}
{"NoViableAltException":{}}
{"DiagnosticErrorListener":{"DiagnosticErrorListener":"\/** \n * Initializes a new instance of  {@link DiagnosticErrorListener}, specifying whether all ambiguities or only exact ambiguities are reported.\n * @param exactOnly {@code true} to report only exact ambiguities, otherwise{@code false} to report all ambiguities.\n *\/\n","getConflictingAlts":"\/** \n * Computes the set of conflicting or ambiguous alternatives from a configuration set, if that information was not already provided by the parser.\n * @param reportedAlts The set of conflicting or ambiguous alternatives, asreported by the parser.\n * @param configs The conflicting or ambiguous configuration set.\n * @return Returns {@code reportedAlts} if it is not {@code null}, otherwise returns the set of alternatives represented in  {@code configs}.\n *\/\n"}}
{"ATNSerializer":{"serialize":"\/** \n * Serialize state descriptors, edge descriptors, and decision&rarr;state map into list of ints: grammar-type, (ANTLRParser.LEXER, ...) max token type, num states, state-0-type ruleIndex, state-1-type ruleIndex, ... state-i-type ruleIndex optional-arg ... num rules, rule-1-start-state rule-1-args, rule-2-start-state  rule-2-args, ... (args are token type,actionIndex in lexer else 0,0) num modes, mode-0-start-state, mode-1-start-state, ... (parser has 0 modes) num unicode-bmp-sets bmp-set-0-interval-count intervals, bmp-set-1-interval-count intervals, ... num unicode-smp-sets smp-set-0-interval-count intervals, smp-set-1-interval-count intervals, ... num total edges, src, trg, edge-type, edge arg1, optional edge arg2 (present always), ... num decisions, decision-0-start-state, decision-1-start-state, ... Convenient to pack into unsigned shorts to make as Java string.\n *\/\n","getSerializedAsString":"\/** \n * Used by Java target to encode short\/int array as chars in string. \n *\/\n"}}
{"PredictionContext":{"fromRuleContext":"\/** \n * Convert a  {@link RuleContext} tree to a {@link PredictionContext} graph.Return  {@link #EMPTY} if {@code outerContext} is empty or null.\n *\/\n","mergeRoot":"\/** \n * Handle case where at least one of  {@code a} or {@code b} is{@link #EMPTY}. In the following diagrams, the symbol  {@code $} is usedto represent  {@link #EMPTY}. <h2>Local-Context Merges<\/h2> <p>These local-context merge operations are used when  {@code rootIsWildcard}is true.<\/p> <p> {@link #EMPTY} is superset of any graph; return {@link #EMPTY}.<br> <embed src=\"images\/LocalMerge_EmptyRoot.svg\" type=\"image\/svg+xml\"\/><\/p> <p> {@link #EMPTY} and anything is {@code #EMPTY}, so merged parent is {@code #EMPTY}; return left graph.<br> <embed src=\"images\/LocalMerge_EmptyParent.svg\" type=\"image\/svg+xml\"\/><\/p> <p>Special case of last merge if local context.<br> <embed src=\"images\/LocalMerge_DiffRoots.svg\" type=\"image\/svg+xml\"\/><\/p> <h2>Full-Context Merges<\/h2> <p>These full-context merge operations are used when  {@code rootIsWildcard}is false.<\/p> <p><embed src=\"images\/FullMerge_EmptyRoots.svg\" type=\"image\/svg+xml\"\/><\/p> <p>Must keep all contexts;  {@link #EMPTY} in array is a special value (andnull parent).<br> <embed src=\"images\/FullMerge_EmptyRoot.svg\" type=\"image\/svg+xml\"\/><\/p> <p><embed src=\"images\/FullMerge_SameRoot.svg\" type=\"image\/svg+xml\"\/><\/p>\n * @param a the first {@link SingletonPredictionContext}\n * @param b the second {@link SingletonPredictionContext}\n * @param rootIsWildcard {@code true} if this is a local-context merge,otherwise false to indicate a full-context merge\n *\/\n","combineCommonParents":"\/** \n * Make pass over all <em>M<\/em>  {@code parents}; merge any  {@code equals()}ones.\n *\/\n","isEmpty":"\/** \n * This means only the  {@link #EMPTY} (wildcard? not sure) context is in set. \n *\/\n","mergeArrays":"\/** \n * Merge two  {@link ArrayPredictionContext} instances.<p>Different tops, different parents.<br> <embed src=\"images\/ArrayMerge_DiffTopDiffPar.svg\" type=\"image\/svg+xml\"\/><\/p> <p>Shared top, same parents.<br> <embed src=\"images\/ArrayMerge_ShareTopSamePar.svg\" type=\"image\/svg+xml\"\/><\/p> <p>Shared top, different parents.<br> <embed src=\"images\/ArrayMerge_ShareTopDiffPar.svg\" type=\"image\/svg+xml\"\/><\/p> <p>Shared top, all shared parents.<br> <embed src=\"images\/ArrayMerge_ShareTopSharePar.svg\" type=\"image\/svg+xml\"\/><\/p> <p>Equal tops, merge parents and reduce top to {@link SingletonPredictionContext}.<br> <embed src=\"images\/ArrayMerge_EqualTop.svg\" type=\"image\/svg+xml\"\/><\/p>\n *\/\n","mergeSingletons":"\/** \n * Merge two  {@link SingletonPredictionContext} instances.<p>Stack tops equal, parents merge is same; return left graph.<br> <embed src=\"images\/SingletonMerge_SameRootSamePar.svg\" type=\"image\/svg+xml\"\/><\/p> <p>Same stack top, parents differ; merge parents giving array node, then remainders of those graphs. A new root node is created to point to the merged parents.<br> <embed src=\"images\/SingletonMerge_SameRootDiffPar.svg\" type=\"image\/svg+xml\"\/><\/p> <p>Different stack tops pointing to same parent. Make array node for the root where both element in the root point to the same (original) parent.<br> <embed src=\"images\/SingletonMerge_DiffRootSamePar.svg\" type=\"image\/svg+xml\"\/><\/p> <p>Different stack tops pointing to different parents. Make array node for the root where each element points to the corresponding original parent.<br> <embed src=\"images\/SingletonMerge_DiffRootDiffPar.svg\" type=\"image\/svg+xml\"\/><\/p>\n * @param a the first {@link SingletonPredictionContext}\n * @param b the second {@link SingletonPredictionContext}\n * @param rootIsWildcard {@code true} if this is a local-context merge,otherwise false to indicate a full-context merge\n * @param mergeCache\n *\/\n"}}
{"Transition":{"isEpsilon":"\/** \n * Determines if the transition is an \"epsilon\" transition. <p>The default implementation returns  {@code false}.<\/p>\n * @return {@code true} if traversing this transition in the ATN does notconsume an input symbol; otherwise,  {@code false} if traversing thistransition consumes (matches) an input symbol.\n *\/\n"}}
{"TokensStartState":{}}
{"StarLoopEntryState":{}}
{"SemanticContext":{"evalPrecedence":"\/** \n * Evaluate the precedence predicates for the context and reduce the result.\n * @param parser The parser instance.\n * @param parserCallStack\n * @return The simplified semantic context after precedence predicates areevaluated, which will be one of the following values. <ul> <li> {@link #NONE}: if the predicate simplifies to  {@code true} afterprecedence predicates are evaluated.<\/li> <li> {@code null}: if the predicate simplifies to  {@code false} afterprecedence predicates are evaluated.<\/li> <li> {@code this}: if the semantic context is not changed as a result of precedence predicate evaluation.<\/li> <li>A non- {@code null} {@link SemanticContext}: the new simplified semantic context after precedence predicates are evaluated.<\/li> <\/ul>\n *\/\n","eval":"\/** \n * {@inheritDoc}<p> The evaluation of predicates by this context is short-circuiting, but unordered.<\/p>\n *\/\n","or":"\/** \n * @see ParserATNSimulator#getPredsForAmbigAlts\n *\/\n","getOperands":"\/** \n * Gets the operands for the semantic context operator.\n * @return a collection of {@link SemanticContext} operands for theoperator.\n * @since 4.3\n *\/\n"}}
{"LookaheadEventInfo":{"LookaheadEventInfo":"\/** \n * Constructs a new instance of the  {@link LookaheadEventInfo} class withthe specified detailed lookahead information.\n * @param decision The decision number\n * @param configs The final configuration set containing the necessaryinformation to determine the result of a prediction, or  {@code null} ifthe final configuration set is not available\n * @param input The input token stream\n * @param startIndex The start index for the current prediction\n * @param stopIndex The index at which the prediction was finally made\n * @param fullCtx {@code true} if the current lookahead is part of an LLprediction; otherwise,  {@code false} if the current lookahead is part ofan SLL prediction\n *\/\n"}}
{"PrecedencePredicateTransition":{}}
{"PredicateEvalInfo":{"PredicateEvalInfo":"\/** \n * Constructs a new instance of the  {@link PredicateEvalInfo} class with thespecified detailed predicate evaluation information.\n * @param decision The decision number\n * @param input The input token stream\n * @param startIndex The start index for the current prediction\n * @param stopIndex The index at which the predicate evaluation wastriggered. Note that the input stream may be reset to other positions for the actual evaluation of individual predicates.\n * @param semctx The semantic context which was evaluated\n * @param evalResult The results of evaluating the semantic context\n * @param predictedAlt The alternative number for the decision which isguarded by the semantic context  {@code semctx}. See  {@link #predictedAlt}for more information.\n * @param fullCtx {@code true} if the semantic context wasevaluated during LL prediction; otherwise,  {@code false} if the semanticcontext was evaluated during SLL prediction\n * @see ParserATNSimulator#evalSemanticContext(SemanticContext,ParserRuleContext,int,boolean)\n * @see SemanticContext#eval(Recognizer,RuleContext)\n *\/\n"}}
{"StarLoopbackState":{}}
{"CodePointTransitions":{"createWithCodePoint":"\/** \n * If  {@code codePoint} is <= U+FFFF, returns a new {@link AtomTransition}. Otherwise, returns a new  {@link SetTransition}.\n *\/\n","createWithCodePointRange":"\/** \n * If  {@code codePointFrom} and {@code codePointTo} are both<= U+FFFF, returns a new  {@link RangeTransition}. Otherwise, returns a new  {@link SetTransition}.\n *\/\n"}}
{"EmptyPredictionContext":{}}
{"PredictionMode":{"hasConfigInRuleStopState":"\/** \n * Checks if any configuration in  {@code configs} is in a{@link RuleStopState}. Configurations meeting this condition have reached the end of the decision rule (local context) or end of start rule (full context).\n * @param configs the configuration set to test\n * @return {@code true} if any configuration in {@code configs} is in a{@link RuleStopState}, otherwise  {@code false}\n *\/\n","hasSLLConflictTerminatingPrediction":"\/** \n * Computes the SLL prediction termination condition. <p> This method computes the SLL prediction termination condition for both of the following cases.<\/p> <ul> <li>The usual SLL+LL fallback upon SLL conflict<\/li> <li>Pure SLL without LL fallback<\/li> <\/ul> <p><strong>COMBINED SLL+LL PARSING<\/strong><\/p> <p>When LL-fallback is enabled upon SLL conflict, correct predictions are ensured regardless of how the termination condition is computed by this method. Due to the substantially higher cost of LL prediction, the prediction should only fall back to LL when the additional lookahead cannot lead to a unique SLL prediction.<\/p> <p>Assuming combined SLL+LL parsing, an SLL configuration set with only conflicting subsets should fall back to full LL, even if the configuration sets don't resolve to the same alternative (e.g. {@code} 1,2}} and  {@code} 3,4}}. If there is at least one non-conflicting configuration, SLL could continue with the hopes that more lookahead will resolve via one of those non-conflicting configurations.<\/p> <p>Here's the prediction termination rule them: SLL (for SLL+LL parsing) stops when it sees only conflicting configuration subsets. In contrast, full LL keeps going when there is uncertainty.<\/p> <p><strong>HEURISTIC<\/strong><\/p> <p>As a heuristic, we stop prediction when we see any conflicting subset unless we see a state that only has one alternative associated with it. The single-alt-state thing lets prediction continue upon rules like (otherwise, it would admit defeat too soon):<\/p> <p> {@code [12|1|[], 6|2|[], 12|2|[]]. s : (ID | ID ID?) ';' ;}<\/p> <p>When the ATN simulation reaches the state before  {@code ';'}, it has a DFA state that looks like:  {@code [12|1|[], 6|2|[], 12|2|[]]}. Naturally {@code 12|1|[]} and {@code 12|2|[]} conflict, but we cannot stopprocessing this node because alternative to has another way to continue, via  {@code [6|2|[]]}.<\/p> <p>It also let's us continue for this rule:<\/p> <p> {@code [1|1|[], 1|2|[], 8|3|[]] a : A | A | A B ;}<\/p> <p>After matching input A, we reach the stop state for rule A, state 1. State 8 is the state right before B. Clearly alternatives 1 and 2 conflict and no amount of further lookahead will separate the two. However, alternative 3 will be able to continue and so we do not stop working on this state. In the previous example, we're concerned with states associated with the conflicting alternatives. Here alt 3 is not associated with the conflicting configs, but since we can continue looking for input reasonably, don't declare the state done.<\/p> <p><strong>PURE SLL PARSING<\/strong><\/p> <p>To handle pure SLL parsing, all we have to do is make sure that we combine stack contexts for configurations that differ only by semantic predicate. From there, we can do the usual SLL termination heuristic.<\/p> <p><strong>PREDICATES IN SLL+LL PARSING<\/strong><\/p> <p>SLL decisions don't evaluate predicates until after they reach DFA stop states because they need to create the DFA cache that works in all semantic situations. In contrast, full LL evaluates predicates collected during start state computation so it can ignore predicates thereafter. This means that SLL termination detection can totally ignore semantic predicates.<\/p> <p>Implementation-wise,  {@link ATNConfigSet} combines stack contexts but notsemantic predicate contexts so we might see two configurations like the following.<\/p> <p> {@code} (s, 1, x, ), (s, 1, x', {p})}<\/p> <p>Before testing these configurations against others, we have to merge {@code x} and {@code x'} (without modifying the existing configurations).For example, we test  {@code (x+x')==x''} when looking for conflicts inthe following configurations.<\/p> <p> {@code} (s, 1, x, ), (s, 1, x', {p}), (s, 2, x'', {})}<\/p> <p>If the configuration set has predicates (as indicated by {@link ATNConfigSet#hasSemanticContext}), this algorithm makes a copy of the configurations to strip out all of the predicates so that a standard {@link ATNConfigSet} will merge everything ignoring predicates.<\/p>\n *\/\n","hasNonConflictingAltSet":"\/** \n * Determines if any single alternative subset in  {@code altsets} containsexactly one alternative.\n * @param altsets a collection of alternative subsets\n * @return {@code true} if {@code altsets} contains a {@link BitSet} with{@link BitSet#cardinality cardinality} 1, otherwise {@code false}\n *\/\n","getConflictingAltSubsets":"\/** \n * This function gets the conflicting alt subsets from a configuration set. For each configuration  {@code c} in {@code configs}: <pre> map[c] U= c. {@link ATNConfig#alt alt} # map hash\/equals uses s and x, notalt and not pred <\/pre>\n *\/\n","allSubsetsConflict":"\/** \n * Determines if every alternative subset in  {@code altsets} contains morethan one alternative.\n * @param altsets a collection of alternative subsets\n * @return {@code true} if every {@link BitSet} in {@code altsets} has{@link BitSet#cardinality cardinality} &gt; 1, otherwise {@code false}\n *\/\n","getUniqueAlt":"\/** \n * Returns the unique alternative predicted by all alternative subsets in {@code altsets}. If no such alternative exists, this method returns {@link ATN#INVALID_ALT_NUMBER}.\n * @param altsets a collection of alternative subsets\n *\/\n","hashCode":"\/** \n * The hash code is only a function of the  {@link ATNState#stateNumber}and  {@link ATNConfig#context}.\n *\/\n","resolvesToJustOneViableAlt":"\/** \n * Full LL prediction termination. <p>Can we stop looking ahead during ATN simulation or is there some uncertainty as to which alternative we will ultimately pick, after consuming more input? Even if there are partial conflicts, we might know that everything is going to resolve to the same minimum alternative. That means we can stop since no more lookahead will change that fact. On the other hand, there might be multiple conflicts that resolve to different minimums. That means we need more look ahead to decide which of those alternatives we should predict.<\/p> <p>The basic idea is to split the set of configurations  {@code C}, into conflicting subsets  {@code (s, _, ctx, _)} and singleton subsets withnon-conflicting configurations. Two configurations conflict if they have identical  {@link ATNConfig#state} and {@link ATNConfig#context} valuesbut different  {@link ATNConfig#alt} value, e.g. {@code (s, i, ctx, _)}and  {@code (s, j, ctx, _)} for {@code i!=j}.<\/p> <p>Reduce these configuration subsets to the set of possible alternatives. You can compute the alternative subsets in one pass as follows:<\/p> <p> {@code} A_s,ctx = i | (s, i, ctx, _)}} for each configuration in {@code C} holding {@code s} and {@code ctx} fixed.<\/p><p>Or in pseudo-code, for each configuration  {@code c} in {@code C}:<\/p> <pre> map[c] U= c. {@link ATNConfig#alt alt} # map hash\/equals uses s and x, notalt and not pred <\/pre> <p>The values in  {@code map} are the set of {@code A_s,ctx} sets.<\/p><p>If  {@code |A_s,ctx|=1} then there is no conflict associated with{@code s} and {@code ctx}.<\/p> <p>Reduce the subsets to singletons by choosing a minimum of each subset. If the union of these alternative subsets is a singleton, then no amount of more lookahead will help us. We will always pick that alternative. If, however, there is more than one alternative, then we are uncertain which alternative to predict and must continue looking for resolution. We may or may not discover an ambiguity in the future, even if there are no conflicting subsets this round.<\/p> <p>The biggest sin is to terminate early because it means we've made a decision but were uncertain as to the eventual outcome. We haven't used enough lookahead. On the other hand, announcing a conflict too late is no big deal; you will still have the conflict. It's just inefficient. It might even look until the end of file.<\/p> <p>No special consideration for semantic predicates is required because predicates are evaluated on-the-fly for full LL prediction, ensuring that no configuration contains a semantic context during the termination check.<\/p> <p><strong>CONFLICTING CONFIGS<\/strong><\/p> <p>Two configurations  {@code (s, i, x)} and {@code (s, j, x')}, conflict when  {@code i!=j} but {@code x=x'}. Because we merge all {@code (s, i, _)} configurations together, that means that there are atmost  {@code n} configurations associated with state {@code s} for{@code n} possible alternatives in the decision. The merged stackscomplicate the comparison of configuration contexts  {@code x} and{@code x'}. Sam checks to see if one is a subset of the other by calling merge and checking to see if the merged result is either  {@code x} or{@code x'}. If the  {@code x} associated with lowest alternative {@code i}is the superset, then  {@code i} is the only possible prediction since theothers resolve to  {@code min(i)} as well. However, if {@code x} isassociated with  {@code j>i} then at least one stack configuration for{@code j} is not in conflict with alternative {@code i}. The algorithm should keep going, looking for more lookahead due to the uncertainty.<\/p> <p>For simplicity, I'm doing a equality check between  {@code x} and{@code x'} that lets the algorithm continue to consume lookahead longerthan necessary. The reason I like the equality is of course the simplicity but also because that is the test you need to detect the alternatives that are actually in conflict.<\/p> <p><strong>CONTINUE\/STOP RULE<\/strong><\/p> <p>Continue if union of resolved alternative sets from non-conflicting and conflicting alternative subsets has more than one alternative. We are uncertain about which alternative to predict.<\/p> <p>The complete set of alternatives,  {@code [i for (_,i,_)]}, tells us which alternatives are still in the running for the amount of input we've consumed at this point. The conflicting sets let us to strip away configurations that won't lead to more states because we resolve conflicts to the configuration with a minimum alternate for the conflicting set.<\/p> <p><strong>CASES<\/strong><\/p> <ul> <li>no conflicts and more than 1 alternative in set =&gt; continue<\/li> <li>  {@code (s, 1, x)},  {@code (s, 2, x)},  {@code (s, 3, z)}, {@code (s', 1, y)},  {@code (s', 2, y)} yields non-conflicting set{@code} 3}} U conflicting sets  {@code} min(1,2})} U  {@code} min(1,2})} = {@code} 1,3}} =&gt; continue <\/li> <li> {@code (s, 1, x)},  {@code (s, 2, x)},  {@code (s', 1, y)}, {@code (s', 2, y)},  {@code (s'', 1, z)} yields non-conflicting set{@code} 1}} U conflicting sets  {@code} min(1,2})} U  {@code} min(1,2})} = {@code} 1}} =&gt; stop and predict 1<\/li> <li> {@code (s, 1, x)},  {@code (s, 2, x)},  {@code (s', 1, y)}, {@code (s', 2, y)} yields conflicting, reduced sets {@code} 1}} U {@code} 1}} =  {@code} 1}} =&gt; stop and predict 1, can announce ambiguity  {@code} 1,2}}<\/li> <li> {@code (s, 1, x)},  {@code (s, 2, x)},  {@code (s', 2, y)}, {@code (s', 3, y)} yields conflicting, reduced sets {@code} 1}} U {@code} 2}} =  {@code} 1,2}} =&gt; continue<\/li> <li> {@code (s, 1, x)},  {@code (s, 2, x)},  {@code (s', 3, y)}, {@code (s', 4, y)} yields conflicting, reduced sets {@code} 1}} U {@code} 3}} =  {@code} 1,3}} =&gt; continue<\/li> <\/ul> <p><strong>EXACT AMBIGUITY DETECTION<\/strong><\/p> <p>If all states report the same conflicting set of alternatives, then we know we have the exact ambiguity set.<\/p> <p><code>|A_<em>i<\/em>|&gt;1<\/code> and <code>A_<em>i<\/em> = A_<em>j<\/em><\/code> for all <em>i<\/em>, <em>j<\/em>.<\/p> <p>In other words, we continue examining lookahead until all  {@code A_i}have more than one alternative and all  {@code A_i} are the same. If{@code} A={1,2}, {1,3}}}, then regular LL prediction would terminate because the resolved set is  {@code} 1}}. To determine what the real ambiguity is, we have to know whether the ambiguity is between one and two or one and three so we keep going. We can only stop prediction when we need exact ambiguity detection when the sets look like {@code} A={1,2}}} or  {@code} {1,2},{1,2}}}, etc...<\/p>\n *\/\n","allSubsetsEqual":"\/** \n * Determines if every alternative subset in  {@code altsets} is equivalent.\n * @param altsets a collection of alternative subsets\n * @return {@code true} if every member of {@code altsets} is equal to theothers, otherwise  {@code false}\n *\/\n","hasConflictingAltSet":"\/** \n * Determines if any single alternative subset in  {@code altsets} containsmore than one alternative.\n * @param altsets a collection of alternative subsets\n * @return {@code true} if {@code altsets} contains a {@link BitSet} with{@link BitSet#cardinality cardinality} &gt; 1, otherwise {@code false}\n *\/\n","getStateToAltMap":"\/** \n * Get a map from state to alt subset from a configuration set. For each configuration  {@code c} in {@code configs}: <pre> map[c. {@link ATNConfig#state state}] U= c. {@link ATNConfig#alt alt}<\/pre>\n *\/\n","allConfigsInRuleStopStates":"\/** \n * Checks if all configurations in  {@code configs} are in a{@link RuleStopState}. Configurations meeting this condition have reached the end of the decision rule (local context) or end of start rule (full context).\n * @param configs the configuration set to test\n * @return {@code true} if all configurations in {@code configs} are in a{@link RuleStopState}, otherwise  {@code false}\n *\/\n","getAlts":"\/** \n * Get union of all alts from configs.\n * @since 4.5.1\n *\/\n"}}
{"ArrayPredictionContext":{}}
{"SetTransition":{}}
{"ProfilingATNSimulator":{}}
{"LexerIndexedCustomAction":{"getActionType":"\/** \n * {@inheritDoc}\n * @return This method returns the result of calling {@link #getActionType}on the  {@link LexerAction} returned by {@link #getAction}.\n *\/\n","LexerIndexedCustomAction":"\/** \n * Constructs a new indexed custom action by associating a character offset with a  {@link LexerAction}. <p>Note: This class is only required for lexer actions for which {@link LexerAction#isPositionDependent} returns {@code true}.<\/p>\n * @param offset The offset into the input {@link CharStream}, relative to the token start index, at which the specified lexer action should be executed.\n * @param action The lexer action to execute at a particular offset in theinput  {@link CharStream}.\n *\/\n","getOffset":"\/** \n * Gets the location in the input  {@link CharStream} at which the lexeraction should be executed. The value is interpreted as an offset relative to the token start index.\n * @return The location in the input {@link CharStream} at which the lexeraction should be executed.\n *\/\n","getAction":"\/** \n * Gets the lexer action to execute.\n * @return A {@link LexerAction} object which executes the lexer action.\n *\/\n","isPositionDependent":"\/** \n * {@inheritDoc}\n * @return This method returns {@code true}.\n *\/\n","execute":"\/** \n * {@inheritDoc}<p>This method calls  {@link #execute} on the result of {@link #getAction}using the provided  {@code lexer}.<\/p>\n *\/\n"}}
{"PlusBlockStartState":{}}
{"PredicateTransition":{}}
{"PredictionContextCache":{"add":"\/** \n * Add a context to the cache and return it. If the context already exists, return that one instead and do not add a new context to the cache. Protect shared cache from unsafe thread access.\n *\/\n"}}
{"AtomTransition":{}}
{"BasicBlockStartState":{}}
{"DecisionEventInfo":{}}
{"ATNState":{}}
{"SingletonPredictionContext":{}}
{"ParserATNSimulator":{"canDropLoopEntryEdgeInLeftRecursiveRule":"\/** \n * Implements first-edge (loop entry) elimination as an optimization during closure operations.  See antlr\/antlr4#1398. The optimization is to avoid adding the loop entry config when the exit path can only lead back to the same StarLoopEntryState after popping context at the rule end state (traversing only epsilon edges, so we're still in closure, in this same rule). We need to detect any state that can reach loop entry on epsilon w\/o exiting rule. We don't have to look at FOLLOW links, just ensure that all stack tops for config refer to key states in LR rule. To verify we are in the right situation we must first check closure is at a StarLoopEntryState generated during LR removal. Then we check that each stack top of context is a return state from one of these cases: 1. 'not' expr, '(' type ')' expr. The return state points at loop entry state 2. expr op expr. The return state is the block end of internal block of (...) 3. 'between' expr 'and' expr. The return state of 2nd expr reference. That state points at block end of internal block of (...)*. 4. expr '?' expr ':' expr. The return state points at block end, which points at loop entry state. If any is true for each stack top, then closure does not add a config to the current config set for edge[0], the loop entry branch. Conditions fail if any context for the current config is: a. empty (we'd fall out of expr to do a global FOLLOW which could even be to some weird spot in expr) or, b. lies outside of expr or, c. lies within expr but at a state not the BlockEndState generated during LR removal Do we need to evaluate predicates ever in closure for this case? No. Predicates, including precedence predicates, are only evaluated when computing a DFA start state. I.e., only before the lookahead (but not parser) consumes a token. There are no epsilon edges allowed in LR rule alt blocks or in the \"primary\" part (ID here). If closure is in StarLoopEntryState any lookahead operation will have consumed a token as there are no epsilon-paths that lead to StarLoopEntryState. We do not have to evaluate predicates therefore if we are in the generated StarLoopEntryState of a LR rule. Note that when making a prediction starting at that decision point, decision d=2, compute-start-state performs closure starting at edges[0], edges[1] emanating from StarLoopEntryState. That means it is not performing closure on StarLoopEntryState during compute-start-state. How do we know this always gives same prediction answer? Without predicates, loop entry and exit paths are ambiguous upon remaining input +b (in, say, a+b). Either paths lead to valid parses. Closure can lead to consuming + immediately or by falling out of this call to expr back into expr and loop back again to StarLoopEntryState to match +b. In this special case, we choose the more efficient path, which is to take the bypass path. The lookahead language has not changed because closure chooses one path over the other. Both paths lead to consuming the same remaining input during a lookahead operation. If the next token is an operator, lookahead will enter the choice block with operators. If it is not, lookahead will exit expr. Same as if closure had chosen to enter the choice block immediately. Closure is examining one config (some loopentrystate, some alt, context) which means it is considering exactly one alt. Closure always copies the same alt to any derived configs. How do we know this optimization doesn't mess up precedence in our parse trees? Looking through expr from left edge of stat only has to confirm that an input, say, a+b+c; begins with any valid interpretation of an expression. The precedence actually doesn't matter when making a decision in stat seeing through expr. It is only when parsing rule expr that we must use the precedence to get the right interpretation and, hence, parse tree.\n * @since 4.6\n *\/\n","dumpDeadEndConfigs":"\/** \n * Used for debugging in adaptivePredict around execATN but I cut it out for clarity now that alg. works well. We can leave this \"dead\" code for a bit.\n *\/\n","getConflictingAlts":"\/** \n * Gets a  {@link BitSet} containing the alternatives in {@code configs}which are part of one or more conflicting alternative subsets.\n * @param configs The {@link ATNConfigSet} to analyze.\n * @return The alternatives in {@code configs} which are part of one or moreconflicting alternative subsets. If  {@code configs} does not contain anyconflicting subsets, this method returns an empty  {@link BitSet}.\n *\/\n","applyPrecedenceFilter":"\/** \n * This method transforms the start state computed by {@link #computeStartState} to the special start state used by aprecedence DFA for a particular precedence value. The transformation process applies the following changes to the start state's configuration set. <ol> <li>Evaluate the precedence predicates for each configuration using {@link SemanticContext#evalPrecedence}.<\/li> <li>When  {@link ATNConfig#isPrecedenceFilterSuppressed} is {@code false}, remove all configurations which predict an alternative greater than 1, for which another configuration that predicts alternative 1 is in the same ATN state with the same prediction context. This transformation is valid for the following reasons: <ul> <li>The closure block cannot contain any epsilon transitions which bypass the body of the closure, so all states reachable via alternative 1 are part of the precedence alternatives of the transformed left-recursive rule.<\/li> <li>The \"primary\" portion of a left recursive rule cannot contain an epsilon transition, so the only way an alternative other than 1 can exist in a state that is also reachable via alternative 1 is by nesting calls to the left-recursive rule, with the outer calls not being at the preferred precedence level. The {@link ATNConfig#isPrecedenceFilterSuppressed} property marks ATNconfigurations which do not meet this condition, and therefore are not eligible for elimination during the filtering process.<\/li> <\/ul> <\/li> <\/ol> <p> The prediction context must be considered by this filter to address situations like the following. <\/p> <code> <pre> grammar TA; prog: statement* EOF; statement: letterA | statement letterA 'b' ; letterA: 'a'; <\/pre> <\/code> <p> If the above grammar, the ATN state immediately before the token reference  {@code 'a'} in {@code letterA} is reachable from the left edgeof both the primary and closure blocks of the left-recursive rule {@code statement}. The prediction context associated with each of these configurations distinguishes between them, and prevents the alternative which stepped out to  {@code prog} (and then back in to {@code statement}from being eliminated by the filter. <\/p>\n * @param configs The configuration set computed by{@link #computeStartState} as the start state for the DFA.\n * @return The transformed configuration set representing the start statefor a precedence DFA at a particular precedence level (determined by calling  {@link Parser#getPrecedence}).\n *\/\n","closure_":"\/** \n * Do the actual work of walking epsilon edges \n *\/\n","addDFAEdge":"\/** \n * Add an edge to the DFA, if possible. This method calls {@link #addDFAState} to ensure the {@code to} state is present in theDFA. If  {@code from} is {@code null}, or if  {@code t} is outside therange of edges that can be represented in the DFA tables, this method returns without adding the edge to the DFA. <p>If  {@code to} is {@code null}, this method returns  {@code null}. Otherwise, this method returns the  {@link DFAState} returned by calling{@link #addDFAState} for the {@code to} state.<\/p>\n * @param dfa The DFA\n * @param from The source state for the edge\n * @param t The input symbol\n * @param to The target state for the edge\n * @return If {@code to} is {@code null}, this method returns  {@code null}; otherwise this method returns the result of calling  {@link #addDFAState}on  {@code to}\n *\/\n","getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule":"\/** \n * This method is used to improve the localization of error messages by choosing an alternative rather than throwing a {@link NoViableAltException} in particular prediction scenarios where the{@link #ERROR} state was reached during ATN simulation.<p> The default implementation of this method uses the following algorithm to identify an ATN configuration which successfully parsed the decision entry rule. Choosing such an alternative ensures that the {@link ParserRuleContext} returned by the calling rule will be completeand valid, and the syntax error will be reported later at a more localized location.<\/p> <ul> <li>If a syntactically valid path or paths reach the end of the decision rule and they are semantically valid if predicated, return the min associated alt.<\/li> <li>Else, if a semantically invalid but syntactically valid path exist or paths exist, return the minimum associated alt. <\/li> <li>Otherwise, return  {@link ATN#INVALID_ALT_NUMBER}.<\/li> <\/ul> <p> In some scenarios, the algorithm described above could predict an alternative which will result in a  {@link FailedPredicateException} inthe parser. Specifically, this could occur if the <em>only<\/em> configuration capable of successfully parsing to the end of the decision rule is blocked by a semantic predicate. By choosing this alternative within {@link #adaptivePredict} instead of throwing a{@link NoViableAltException}, the resulting {@link FailedPredicateException} in the parser will identify the specificpredicate which is preventing the parser from successfully parsing the decision rule, which helps developers identify and correct logic errors in semantic predicates. <\/p>\n * @param configs The ATN configurations which were valid immediately beforethe  {@link #ERROR} state was reached\n * @param outerContext The is the \\gamma_0 initial parser context from the paperor the parser stack at the instant before prediction commences.\n * @return The value to return from {@link #adaptivePredict}, or {@link ATN#INVALID_ALT_NUMBER} if a suitable alternative was notidentified and  {@link #adaptivePredict} should report an error instead.\n *\/\n","evalSemanticContext":"\/** \n * Evaluate a semantic context within a specific parser context. <p> This method might not be called for every semantic context evaluated during the prediction process. In particular, we currently do not evaluate the following but it may change in the future:<\/p> <ul> <li>Precedence predicates (represented by {@link SemanticContext.PrecedencePredicate}) are not currently evaluated through this method.<\/li> <li>Operator predicates (represented by  {@link SemanticContext.AND} and{@link SemanticContext.OR}) are evaluated as a single semantic context, rather than evaluating the operands individually. Implementations which require evaluation results from individual predicates should override this method to explicitly handle evaluation of the operands within operator predicates.<\/li> <\/ul>\n * @param pred The semantic context to evaluate\n * @param parserCallStack The parser context in which to evaluate thesemantic context\n * @param alt The alternative which is guarded by {@code pred}\n * @param fullCtx {@code true} if the evaluation is occurring during LLprediction; otherwise,  {@code false} if the evaluation is occurringduring SLL prediction\n * @since 4.3\n *\/\n","execATN":"\/** \n * Performs ATN simulation to compute a predicted alternative based upon the remaining input, but also updates the DFA cache to avoid having to traverse the ATN again for the same input sequence. There are some key conditions we're looking for after computing a new set of ATN configs (proposed DFA state): if the set is empty, there is no viable alternative for current symbol does the state uniquely predict an alternative? does the state have a conflict that would prevent us from putting it on the work list? We also have some key operations to do: add an edge from previous DFA state to potentially new DFA state, D, upon current symbol but only if adding to work list, which means in all cases except no viable alternative (and possibly non-greedy decisions?) collecting predicates and adding semantic context to DFA accept states adding rule context to context-sensitive DFA accept states consuming an input symbol reporting a conflict reporting an ambiguity reporting a context sensitivity reporting insufficient predicates cover these cases: dead end single alt single alt + preds conflict conflict + preds\n *\/\n","removeAllConfigsNotInRuleStopState":"\/** \n * Return a configuration set containing only the configurations from {@code configs} which are in a {@link RuleStopState}. If all configurations in  {@code configs} are already in a rule stop state, thismethod simply returns  {@code configs}. <p>When  {@code lookToEndOfRule} is true, this method uses{@link ATN#nextTokens} for each configuration in {@code configs} which isnot already in a rule stop state to see if a rule stop state is reachable from the configuration via epsilon-only transitions.<\/p>\n * @param configs the configuration set to update\n * @param lookToEndOfRule when true, this method checks for rule stop statesreachable by epsilon-only transitions from each configuration in {@code configs}.\n * @return {@code configs} if all configurations in {@code configs} are in arule stop state, otherwise return a new configuration set containing only the configurations from  {@code configs} which are in a rule stop state\n *\/\n","getConflictingAltsOrUniqueAlt":"\/** \n * Sam pointed out a problem with the previous definition, v3, of ambiguous states. If we have another state associated with conflicting alternatives, we should keep going. For example, the following grammar s : (ID | ID ID?) ';' ; When the ATN simulation reaches the state before ';', it has a DFA state that looks like: [12|1|[], 6|2|[], 12|2|[]]. Naturally 12|1|[] and 12|2|[] conflict, but we cannot stop processing this node because alternative to has another way to continue, via [6|2|[]]. The key is that we have a single state that has config's only associated with a single alternative, 2, and crucially the state transitions among the configurations are all non-epsilon transitions. That means we don't consider any conflicts that include alternative 2. So, we ignore the conflict between alts 1 and 2. We ignore a set of conflicting alts when there is an intersection with an alternative associated with a single alt state in the state&rarr;config-list map. It's also the case that we might have two conflicting configurations but also a 3rd nonconflicting configuration for a different alternative: [1|1|[], 1|2|[], 8|3|[]]. This can come about from grammar: a : A | A | A B ; After matching input A, we reach the stop state for rule A, state 1. State 8 is the state right before B. Clearly alternatives 1 and 2 conflict and no amount of further lookahead will separate the two. However, alternative 3 will be able to continue and so we do not stop working on this state. In the previous example, we're concerned with states associated with the conflicting alternatives. Here alt 3 is not associated with the conflicting configs, but since we can continue looking for input reasonably, I don't declare the state done. We ignore a set of conflicting alts when we have an alternative that we still need to pursue.\n *\/\n","computeTargetState":"\/** \n * Compute a target state for an edge in the DFA, and attempt to add the computed state and corresponding edge to the DFA.\n * @param dfa The DFA\n * @param previousD The current DFA state\n * @param t The next input symbol\n * @return The computed target DFA state for the given input symbol{@code t}. If  {@code t} does not lead to a valid DFA state, this methodreturns  {@link #ERROR}.\n *\/\n","getParser":"\/** \n * @since 4.3\n *\/\n","getExistingTargetState":"\/** \n * Get an existing target state for an edge in the DFA. If the target state for the edge has not yet been computed or is otherwise not available, this method returns  {@code null}.\n * @param previousD The current DFA state\n * @param t The next input symbol\n * @return The existing target DFA state for the given input symbol{@code t}, or  {@code null} if the target state for this edge is notalready cached\n *\/\n","addDFAState":"\/** \n * Add state  {@code D} to the DFA if it is not already present, and returnthe actual instance stored in the DFA. If a state equivalent to  {@code D}is already in the DFA, the existing state is returned. Otherwise this method returns  {@code D} after adding it to the DFA.<p>If  {@code D} is {@link #ERROR}, this method returns  {@link #ERROR} anddoes not change the DFA.<\/p>\n * @param dfa The dfa\n * @param D The DFA state to add\n * @return The state stored in the DFA. This will be either the existingstate if  {@code D} is already in the DFA, or {@code D} itself if thestate was not already present.\n *\/\n","reportAmbiguity":"\/** \n * If context sensitive parsing, we know it's ambiguity not conflict \n *\/\n","ParserATNSimulator":"\/** \n * Testing only! \n *\/\n","splitAccordingToSemanticValidity":"\/** \n * Walk the list of configurations and split them according to those that have preds evaluating to true\/false.  If no pred, assume true pred and include in succeeded set.  Returns Pair of sets. Create a new set so as not to alter the incoming parameter. Assumption: the input stream has been restored to the starting point prediction, which is where predicates need to evaluate.\n *\/\n"}}
{"WildcardTransition":{}}
{"ATNConfig":{"equals":"\/** \n * An ATN configuration is equal to another if both have the same state, they predict the same alternative, and syntactic\/semantic contexts are the same.\n *\/\n","getOuterContextDepth":"\/** \n * This method gets the value of the  {@link #reachesIntoOuterContext} fieldas it existed prior to the introduction of the {@link #isPrecedenceFilterSuppressed} method.\n *\/\n"}}
{"RuleTransition":{"RuleTransition":"\/** \n * @deprecated Use{@link #RuleTransition(RuleStartState,int,int,ATNState)} instead.\n *\/\n"}}
{"LexerSkipAction":{"LexerSkipAction":"\/** \n * Constructs the singleton instance of the lexer  {@code skip} command.\n *\/\n","getActionType":"\/** \n * {@inheritDoc}\n * @return This method returns {@link LexerActionType#SKIP}.\n *\/\n","isPositionDependent":"\/** \n * {@inheritDoc}\n * @return This method returns {@code false}.\n *\/\n","execute":"\/** \n * {@inheritDoc}<p>This action is implemented by calling  {@link Lexer#skip}.<\/p>\n *\/\n"}}
{"LexerMoreAction":{"getActionType":"\/** \n * {@inheritDoc}\n * @return This method returns {@link LexerActionType#MORE}.\n *\/\n","LexerMoreAction":"\/** \n * Constructs the singleton instance of the lexer  {@code more} command.\n *\/\n","isPositionDependent":"\/** \n * {@inheritDoc}\n * @return This method returns {@code false}.\n *\/\n","execute":"\/** \n * {@inheritDoc}<p>This action is implemented by calling  {@link Lexer#more}.<\/p>\n *\/\n"}}
{"LexerATNSimulator":{"getReachableConfigSet":"\/** \n * Given a starting configuration set, figure out all ATN configurations we can reach upon input  {@code t}. Parameter  {@code reach} is a returnparameter.\n *\/\n","evaluatePredicate":"\/** \n * Evaluate a predicate specified in the lexer. <p>If  {@code speculative} is {@code true}, this method was called before {@link #consume} for the matched character. This method should call{@link #consume} before evaluating the predicate to ensure positionsensitive values, including  {@link Lexer#getText},  {@link Lexer#getLine}, and  {@link Lexer#getCharPositionInLine}, properly reflect the current lexer state. This method should restore  {@code input} and the simulatorto the original state before returning (i.e. undo the actions made by the call to  {@link #consume}.<\/p>\n * @param input The input stream.\n * @param ruleIndex The rule containing the predicate.\n * @param predIndex The index of the predicate within the rule.\n * @param speculative {@code true} if the current index in {@code input} isone character before the predicate's location.\n * @return {@code true} if the specified predicate evaluates to{@code true}.\n *\/\n","getText":"\/** \n * Get the text matched so far for the current token.\n *\/\n","computeTargetState":"\/** \n * Compute a target state for an edge in the DFA, and attempt to add the computed state and corresponding edge to the DFA.\n * @param input The input stream\n * @param s The current DFA state\n * @param t The next input symbol\n * @return The computed target DFA state for the given input symbol{@code t}. If  {@code t} does not lead to a valid DFA state, this methodreturns  {@link #ERROR}.\n *\/\n","getExistingTargetState":"\/** \n * Get an existing target state for an edge in the DFA. If the target state for the edge has not yet been computed or is otherwise not available, this method returns  {@code null}.\n * @param s The current DFA state\n * @param t The next input symbol\n * @return The existing target DFA state for the given input symbol{@code t}, or  {@code null} if the target state for this edge is notalready cached\n *\/\n","addDFAState":"\/** \n * Add a new DFA state if there isn't one with this set of configurations already. This method also detects the first configuration containing an ATN rule stop state. Later, when traversing the DFA, we will know which rule to accept.\n *\/\n","closure":"\/** \n * Since the alternatives within any lexer decision are ordered by preference, this method stops pursuing the closure as soon as an accept state is reached. After the first accept state is reached by depth-first search from  {@code config}, all other (potentially reachable) states for this rule would have a lower priority.\n * @return {@code true} if an accept state is reached, otherwise{@code false}.\n *\/\n"}}
{"ActionTransition":{}}
{"LexerModeAction":{"getActionType":"\/** \n * {@inheritDoc}\n * @return This method returns {@link LexerActionType#MODE}.\n *\/\n","LexerModeAction":"\/** \n * Constructs a new  {@code mode} action with the specified mode value.\n * @param mode The mode value to pass to {@link Lexer#mode}.\n *\/\n","getMode":"\/** \n * Get the lexer mode this action should transition the lexer to.\n * @return The lexer mode for this {@code mode} command.\n *\/\n","isPositionDependent":"\/** \n * {@inheritDoc}\n * @return This method returns {@code false}.\n *\/\n","execute":"\/** \n * {@inheritDoc}<p>This action is implemented by calling  {@link Lexer#mode} with thevalue provided by  {@link #getMode}.<\/p>\n *\/\n"}}
{"ContextSensitivityInfo":{"ContextSensitivityInfo":"\/** \n * Constructs a new instance of the  {@link ContextSensitivityInfo} classwith the specified detailed context sensitivity information.\n * @param decision The decision number\n * @param configs The final configuration set containing the uniquealternative identified by full-context prediction\n * @param input The input token stream\n * @param startIndex The start index for the current prediction\n * @param stopIndex The index at which the context sensitivity wasidentified during full-context prediction\n *\/\n"}}
{"ATN":{"getExpectedTokens":"\/** \n * Computes the set of input symbols which could follow ATN state number {@code stateNumber} in the specified full {@code context}. This method considers the complete parser context, but does not evaluate semantic predicates (i.e. all predicates encountered during the calculation are assumed true). If a path in the ATN exists from the starting state to the {@link RuleStopState} of the outermost context without matching anysymbols,  {@link Token#EOF} is added to the returned set.<p>If  {@code context} is {@code null}, it is treated as  {@link ParserRuleContext#EMPTY}.<\/p> Note that this does NOT give you the set of all tokens that could appear at a given token position in the input phrase.  In other words, it does not answer: \"Given a specific partial input phrase, return the set of all tokens that can follow the last token in the input phrase.\" The big difference is that with just the input, the parser could land right in the middle of a lookahead decision. Getting all *possible* tokens given a partial input stream is a separate computation. See https:\/\/github.com\/antlr\/antlr4\/issues\/1428 For this function, we are specifying an ATN state and call stack to compute what token(s) can come next and specifically: outside of a lookahead decision. That is what you want for error reporting and recovery upon parse error.\n * @param stateNumber the ATN state number\n * @param context the full parse context\n * @return The set of potentially valid input symbols which could follow thespecified state in the specified context.\n * @throws IllegalArgumentException if the ATN does not contain a state withnumber  {@code stateNumber}\n *\/\n","ATN":"\/** \n * Used for runtime deserialization of ATNs from strings \n *\/\n","nextTokens":"\/** \n * Compute the set of valid tokens that can occur starting in  {@code s} andstaying in same rule.  {@link Token#EPSILON} is in set if we reach end ofrule.\n *\/\n"}}
{"ErrorInfo":{"ErrorInfo":"\/** \n * Constructs a new instance of the  {@link ErrorInfo} class with thespecified detailed syntax error information.\n * @param decision The decision number\n * @param configs The final configuration set reached during predictionprior to reaching the  {@link ATNSimulator#ERROR} state\n * @param input The input token stream\n * @param startIndex The start index for the current prediction\n * @param stopIndex The index at which the syntax error was identified\n * @param fullCtx {@code true} if the syntax error was identified during LLprediction; otherwise,  {@code false} if the syntax error was identifiedduring SLL prediction\n *\/\n"}}
{"EpsilonTransition":{"outermostPrecedenceReturn":"\/** \n * @return the rule index of a precedence rule for which this transition isreturning from, where the precedence value is 0; otherwise, -1.\n * @see ATNConfig#isPrecedenceFilterSuppressed()\n * @see ParserATNSimulator#applyPrecedenceFilter(ATNConfigSet)\n * @since 4.4.1\n *\/\n"}}
{"BasicState":{}}
{"AmbiguityInfo":{"AmbiguityInfo":"\/** \n * Constructs a new instance of the  {@link AmbiguityInfo} class with thespecified detailed ambiguity information.\n * @param decision The decision number\n * @param configs The final configuration set identifying the ambiguousalternatives for the current input\n * @param ambigAlts The set of alternatives in the decision that lead to a valid parse.The predicted alt is the min(ambigAlts)\n * @param input The input token stream\n * @param startIndex The start index for the current prediction\n * @param stopIndex The index at which the ambiguity was identified duringprediction\n * @param fullCtx {@code true} if the ambiguity was identified during LLprediction; otherwise,  {@code false} if the ambiguity was identifiedduring SLL prediction\n *\/\n"}}
{"PlusLoopbackState":{}}
{"LexerCustomAction":{"getRuleIndex":"\/** \n * Gets the rule index to use for calls to  {@link Recognizer#action}.\n * @return The rule index for the custom action.\n *\/\n","getActionType":"\/** \n * {@inheritDoc}\n * @return This method returns {@link LexerActionType#CUSTOM}.\n *\/\n","getActionIndex":"\/** \n * Gets the action index to use for calls to  {@link Recognizer#action}.\n * @return The action index for the custom action.\n *\/\n","LexerCustomAction":"\/** \n * Constructs a custom lexer action with the specified rule and action indexes.\n * @param ruleIndex The rule index to use for calls to{@link Recognizer#action}.\n * @param actionIndex The action index to use for calls to{@link Recognizer#action}.\n *\/\n","isPositionDependent":"\/** \n * Gets whether the lexer action is position-dependent. Position-dependent actions may have different semantics depending on the  {@link CharStream}index at the time the action is executed. <p>Custom actions are position-dependent since they may represent a user-defined embedded action which makes calls to methods like {@link Lexer#getText}.<\/p>\n * @return This method returns {@code true}.\n *\/\n","execute":"\/** \n * {@inheritDoc}<p>Custom actions are implemented by calling  {@link Lexer#action} with theappropriate rule and action indexes.<\/p>\n *\/\n"}}
{"BlockStartState":{}}
{"RuleStartState":{}}
{"DecisionInfo":{"DecisionInfo":"\/** \n * Constructs a new instance of the  {@link DecisionInfo} class to containstatistics for a particular decision.\n * @param decision The decision number\n *\/\n"}}
{"LL1Analyzer":{"_LOOK":"\/** \n * Compute set of tokens that can follow  {@code s} in the ATN in thespecified  {@code ctx}. <p>If  {@code ctx} is {@code null} and {@code stopState} or the end of therule containing  {@code s} is reached, {@link Token#EPSILON} is added tothe result set. If  {@code ctx} is not {@code null} and {@code addEOF} is{@code true} and {@code stopState} or the end of the outermost rule isreached,  {@link Token#EOF} is added to the result set.<\/p>\n * @param s the ATN state.\n * @param stopState the ATN state to stop at. This can be a{@link BlockEndState} to detect epsilon paths through a closure.\n * @param ctx The outer context, or {@code null} if the outer context shouldnot be used.\n * @param look The result lookahead set.\n * @param lookBusy A set used for preventing epsilon closures in the ATNfrom causing a stack overflow. Outside code should pass {@code new HashSet<ATNConfig>} for this argument.\n * @param calledRuleStack A set used for preventing left recursion in theATN from causing a stack overflow. Outside code should pass {@code new BitSet()} for this argument.\n * @param seeThruPreds {@code true} to true semantic predicates asimplicitly  {@code true} and \"see through them\", otherwise {@code false}to treat semantic predicates as opaque and add  {@link #HIT_PRED} to theresult if one is encountered.\n * @param addEOF Add {@link Token#EOF} to the result if the end of theoutermost context is reached. This parameter has no effect if  {@code ctx}is  {@code null}.\n *\/\n","getDecisionLookahead":"\/** \n * Calculates the SLL(1) expected lookahead set for each outgoing transition of an  {@link ATNState}. The returned array has one element for each outgoing transition in  {@code s}. If the closure from transition <em>i<\/em> leads to a semantic predicate before matching a symbol, the element at index <em>i<\/em> of the result will be  {@code null}.\n * @param s the ATN state\n * @return the expected symbols for each outgoing transition of {@code s}.\n *\/\n","LOOK":"\/** \n * Compute set of tokens that can follow  {@code s} in the ATN in thespecified  {@code ctx}. <p>If  {@code ctx} is {@code null} and the end of the rule containing{@code s} is reached, {@link Token#EPSILON} is added to the result set.If  {@code ctx} is not {@code null} and the end of the outermost rule isreached,  {@link Token#EOF} is added to the result set.<\/p>\n * @param s the ATN state\n * @param stopState the ATN state to stop at. This can be a{@link BlockEndState} to detect epsilon paths through a closure.\n * @param ctx the complete parser context, or {@code null} if the contextshould be ignored\n * @return The set of tokens that can follow {@code s} in the ATN in thespecified  {@code ctx}.\n *\/\n"}}
{"LexerPopModeAction":{"getActionType":"\/** \n * {@inheritDoc}\n * @return This method returns {@link LexerActionType#POP_MODE}.\n *\/\n","isPositionDependent":"\/** \n * {@inheritDoc}\n * @return This method returns {@code false}.\n *\/\n","execute":"\/** \n * {@inheritDoc}<p>This action is implemented by calling  {@link Lexer#popMode}.<\/p>\n *\/\n","LexerPopModeAction":"\/** \n * Constructs the singleton instance of the lexer  {@code popMode} command.\n *\/\n"}}
{"ATNDeserializer":{"markPrecedenceDecisions":"\/** \n * Analyze the  {@link StarLoopEntryState} states in the specified ATN to setthe  {@link StarLoopEntryState#isPrecedenceDecision} field to thecorrect value.\n * @param atn The ATN.\n *\/\n","isFeatureSupported":"\/** \n * Determines if a particular serialized representation of an ATN supports a particular feature, identified by the  {@link UUID} used for serializingthe ATN at the time the feature was first introduced.\n * @param feature The {@link UUID} marking the first time the feature wassupported in the serialized ATN.\n * @param actualUuid The {@link UUID} of the actual serialized ATN which iscurrently being deserialized.\n * @return {@code true} if the {@code actualUuid} value represents aserialized ATN at or after the feature identified by  {@code feature} wasintroduced; otherwise,  {@code false}.\n *\/\n"}}
{"NotSetTransition":{}}
{"LexerPushModeAction":{"LexerPushModeAction":"\/** \n * Constructs a new  {@code pushMode} action with the specified mode value.\n * @param mode The mode value to pass to {@link Lexer#pushMode}.\n *\/\n","getActionType":"\/** \n * {@inheritDoc}\n * @return This method returns {@link LexerActionType#PUSH_MODE}.\n *\/\n","getMode":"\/** \n * Get the lexer mode this action should transition the lexer to.\n * @return The lexer mode for this {@code pushMode} command.\n *\/\n","isPositionDependent":"\/** \n * {@inheritDoc}\n * @return This method returns {@code false}.\n *\/\n","execute":"\/** \n * {@inheritDoc}<p>This action is implemented by calling  {@link Lexer#pushMode} with thevalue provided by  {@link #getMode}.<\/p>\n *\/\n"}}
{"LexerTypeAction":{"getActionType":"\/** \n * {@inheritDoc}\n * @return This method returns {@link LexerActionType#TYPE}.\n *\/\n","getType":"\/** \n * Gets the type to assign to a token created by the lexer.\n * @return The type to assign to a token created by the lexer.\n *\/\n","LexerTypeAction":"\/** \n * Constructs a new  {@code type} action with the specified token type value.\n * @param type The type to assign to the token using {@link Lexer#setType}.\n *\/\n","isPositionDependent":"\/** \n * {@inheritDoc}\n * @return This method returns {@code false}.\n *\/\n","execute":"\/** \n * {@inheritDoc}<p>This action is implemented by calling  {@link Lexer#setType} with thevalue provided by  {@link #getType}.<\/p>\n *\/\n"}}
{"OrderedATNConfigSet":{}}
{"DecisionState":{}}
{"LexerATNConfig":{"getLexerActionExecutor":"\/** \n * Gets the  {@link LexerActionExecutor} capable of executing the embeddedaction(s) for the current configuration.\n *\/\n"}}
{"RangeTransition":{}}
{"LexerChannelAction":{"getActionType":"\/** \n * {@inheritDoc}\n * @return This method returns {@link LexerActionType#CHANNEL}.\n *\/\n","LexerChannelAction":"\/** \n * Constructs a new  {@code channel} action with the specified channel value.\n * @param channel The channel value to pass to {@link Lexer#setChannel}.\n *\/\n","getChannel":"\/** \n * Gets the channel to use for the  {@link Token} created by the lexer.\n * @return The channel to use for the {@link Token} created by the lexer.\n *\/\n","isPositionDependent":"\/** \n * {@inheritDoc}\n * @return This method returns {@code false}.\n *\/\n","execute":"\/** \n * {@inheritDoc}<p>This action is implemented by calling  {@link Lexer#setChannel} with thevalue provided by  {@link #getChannel}.<\/p>\n *\/\n"}}
{"ATNConfigSet":{"add":"\/** \n * Adding a new config means merging contexts with existing configs for {@code (s, i, pi, _)}, where  {@code s} is the{@link ATNConfig#state},  {@code i} is the {@link ATNConfig#alt}, and {@code pi} is the {@link ATNConfig#semanticContext}. We use {@code (s,i,pi)} as key.<p>This method updates  {@link #dipsIntoOuterContext} and{@link #hasSemanticContext} when necessary.<\/p>\n *\/\n","elements":"\/** \n * Return a List holding list of configs \n *\/\n","getAlts":"\/** \n * Gets the complete set of represented alternatives for the configuration set.\n * @return the set of represented alternatives in this configuration set\n * @since 4.3\n *\/\n"}}
{"LexerAction":{"getActionType":"\/** \n * Gets the serialization type of the lexer action.\n * @return The serialization type of the lexer action.\n *\/\n","isPositionDependent":"\/** \n * Gets whether the lexer action is position-dependent. Position-dependent actions may have different semantics depending on the  {@link CharStream}index at the time the action is executed. <p>Many lexer commands, including  {@code type},  {@code skip}, and {@code more}, do not check the input index during their execution. Actions like this are position-independent, and may be stored more efficiently as part of the  {@link LexerATNConfig#lexerActionExecutor}.<\/p>\n * @return {@code true} if the lexer action semantics can be affected by theposition of the input  {@link CharStream} at the time it is executed;otherwise,  {@code false}.\n *\/\n","execute":"\/** \n * Execute the lexer action in the context of the specified  {@link Lexer}. <p>For position-dependent actions, the input stream must already be positioned correctly prior to calling this method.<\/p>\n * @param lexer The lexer instance.\n *\/\n"}}
{"StarBlockStartState":{}}
{"LexerActionExecutor":{"fixOffsetBeforeMatch":"\/** \n * Creates a  {@link LexerActionExecutor} which encodes the current offsetfor position-dependent lexer actions. <p>Normally, when the executor encounters lexer actions where {@link LexerAction#isPositionDependent} returns {@code true}, it calls {@link IntStream#seek} on the input {@link CharStream} to set the inputposition to the <em>end<\/em> of the current token. This behavior provides for efficient DFA representation of lexer actions which appear at the end of a lexer rule, even when the lexer rule matches a variable number of characters.<\/p> <p>Prior to traversing a match transition in the ATN, the current offset from the token start index is assigned to all position-dependent lexer actions which have not already been assigned a fixed offset. By storing the offsets relative to the token start index, the DFA representation of lexer actions which appear in the middle of tokens remains efficient due to sharing among tokens of the same length, regardless of their absolute position in the input stream.<\/p> <p>If the current executor already has offsets assigned to all position-dependent lexer actions, the method returns  {@code this}.<\/p>\n * @param offset The current offset to assign to all position-dependentlexer actions which do not already have offsets assigned.\n * @return A {@link LexerActionExecutor} which stores input stream offsetsfor all position-dependent lexer actions.\n *\/\n","LexerActionExecutor":"\/** \n * Constructs an executor for a sequence of  {@link LexerAction} actions.\n * @param lexerActions The lexer actions to execute.\n *\/\n","getLexerActions":"\/** \n * Gets the lexer actions to be executed by this executor.\n * @return The lexer actions to be executed by this executor.\n *\/\n","execute":"\/** \n * Execute the actions encapsulated by this executor within the context of a particular  {@link Lexer}. <p>This method calls  {@link IntStream#seek} to set the position of the{@code input} {@link CharStream} prior to calling{@link LexerAction#execute} on a position-dependent action. Before themethod returns, the input position will be restored to the same position it was in when the method was invoked.<\/p>\n * @param lexer The lexer instance.\n * @param input The input stream which is the source for the current token.When this method is called, the current  {@link IntStream#index} for{@code input} should be the start of the following token, i.e. 1character past the end of the current token.\n * @param startIndex The token start index. This value may be passed to{@link IntStream#seek} to set the {@code input} position to the beginningof the token.\n *\/\n","append":"\/** \n * Creates a  {@link LexerActionExecutor} which executes the actions forthe input  {@code lexerActionExecutor} followed by a specified{@code lexerAction}.\n * @param lexerActionExecutor The executor for actions already traversed bythe lexer while matching a token within a particular {@link LexerATNConfig}. If this is  {@code null}, the method behaves as though it were an empty executor.\n * @param lexerAction The lexer action to execute after the actionsspecified in  {@code lexerActionExecutor}.\n * @return A {@link LexerActionExecutor} for executing the combine actionsof  {@code lexerActionExecutor} and {@code lexerAction}.\n *\/\n"}}
{"LexerActionType":{}}
{"BlockEndState":{}}
{"LoopEndState":{}}
{"AbstractPredicateTransition":{}}
{"ParseInfo":{"getTotalSLLLookaheadOps":"\/** \n * Gets the total number of SLL lookahead operations across all decisions made during parsing. This value is the sum of {@link DecisionInfo#SLL_TotalLook} for all decisions.\n *\/\n","getDFASize":"\/** \n * Gets the total number of DFA states stored in the DFA cache for a particular decision.\n *\/\n","getTotalATNLookaheadOps":"\/** \n * Gets the total number of ATN lookahead operations for SLL and LL prediction across all decisions made during parsing. <p> This value is the sum of  {@link #getTotalSLLATNLookaheadOps} and{@link #getTotalLLATNLookaheadOps}.<\/p>\n *\/\n","getTotalTimeInPrediction":"\/** \n * Gets the total time spent during prediction across all decisions made during parsing. This value is the sum of {@link DecisionInfo#timeInPrediction} for all decisions.\n *\/\n","getTotalLLATNLookaheadOps":"\/** \n * Gets the total number of ATN lookahead operations for LL prediction across all decisions made during parsing.\n *\/\n","getDecisionInfo":"\/** \n * Gets an array of  {@link DecisionInfo} instances containing the profilinginformation gathered for each decision in the ATN.\n * @return An array of {@link DecisionInfo} instances, indexed by decisionnumber.\n *\/\n","getTotalSLLATNLookaheadOps":"\/** \n * Gets the total number of ATN lookahead operations for SLL prediction across all decisions made during parsing.\n *\/\n","getTotalLLLookaheadOps":"\/** \n * Gets the total number of LL lookahead operations across all decisions made during parsing. This value is the sum of {@link DecisionInfo#LL_TotalLook} for all decisions.\n *\/\n","getLLDecisions":"\/** \n * Gets the decision numbers for decisions that required one or more full-context predictions during parsing. These are decisions for which {@link DecisionInfo#LL_Fallback} is non-zero.\n * @return A list of decision numbers which required one or morefull-context predictions during parsing.\n *\/\n"}}
{"RuleStopState":{}}
{"ATNSimulator":{"toUUID":"\/** \n * @deprecated Use {@link ATNDeserializer#toUUID} instead.\n *\/\n","edgeFactory":"\/** \n * @deprecated Use {@link ATNDeserializer#edgeFactory} instead.\n *\/\n","toInt":"\/** \n * @deprecated Use {@link ATNDeserializer#toInt} instead.\n *\/\n","toLong":"\/** \n * @deprecated Use {@link ATNDeserializer#toLong} instead.\n *\/\n","toInt32":"\/** \n * @deprecated Use {@link ATNDeserializer#toInt32} instead.\n *\/\n","checkCondition":"\/** \n * @deprecated Use {@link ATNDeserializer#checkCondition(boolean,String)} instead.\n *\/\n","stateFactory":"\/** \n * @deprecated Use {@link ATNDeserializer#stateFactory} instead.\n *\/\n","clearDFA":"\/** \n * Clear the DFA cache used by the current instance. Since the DFA cache may be shared by multiple ATN simulators, this method may affect the performance (but not accuracy) of other parsers which are being used concurrently.\n * @throws UnsupportedOperationException if the current instance does notsupport clearing the DFA.\n * @since 4.3\n *\/\n","deserialize":"\/** \n * @deprecated Use {@link ATNDeserializer#deserialize} instead.\n *\/\n"}}
{"ATNDeserializationOptions":{}}
{"ATNType":{}}
{"Token":{"getStopIndex":"\/** \n * The last character index of the token. This method is optional; return -1 if not implemented.\n *\/\n","getType":"\/** \n * Get the token type of the token \n *\/\n","getChannel":"\/** \n * Return the channel this token. Each token can arrive at the parser on a different channel, but the parser only \"tunes\" to a single channel. The parser ignores everything not on DEFAULT_CHANNEL.\n *\/\n","getStartIndex":"\/** \n * The starting character index of the token This method is optional; return -1 if not implemented.\n *\/\n","getText":"\/** \n * Get the text of the token.\n *\/\n","getCharPositionInLine":"\/** \n * The index of the first character of this token relative to the beginning of the line at which it occurs, 0..n-1\n *\/\n","getLine":"\/** \n * The line number on which the 1st character of this token was matched, line=1..n\n *\/\n","getTokenIndex":"\/** \n * An index from 0..n-1 of the token object in the input stream. This must be valid in order to print token streams and use TokenRewriteStream. Return -1 to indicate that this token was conjured up since it doesn't have a valid index.\n *\/\n","getTokenSource":"\/** \n * Gets the  {@link TokenSource} which created this token.\n *\/\n","getInputStream":"\/** \n * Gets the  {@link CharStream} from which this token was derived.\n *\/\n"}}
{"Vocabulary":{"getDisplayName":"\/** \n * Gets the display name of a token type. <p>ANTLR provides a default implementation of this method, but applications are free to override the behavior in any manner which makes sense for the application. The default implementation returns the first result from the following list which produces a non- {@code null}result.<\/p> <ol> <li>The result of  {@link #getLiteralName}<\/li> <li>The result of  {@link #getSymbolicName}<\/li> <li>The result of  {@link Integer#toString}<\/li> <\/ol>\n * @param tokenType The token type.\n * @return The display name of the token type, for use in error reporting orother user-visible messages which reference specific token types.\n *\/\n","getLiteralName":"\/** \n * Gets the string literal associated with a token type. The string returned by this method, when not  {@code null}, can be used unaltered in a parser grammar to represent this token type. <p>The following table shows examples of lexer rules and the literal names assigned to the corresponding token types.<\/p> <table> <tr> <th>Rule<\/th> <th>Literal Name<\/th> <th>Java String Literal<\/th> <\/tr> <tr> <td> {@code THIS : 'this';}<\/td> <td> {@code 'this'}<\/td> <td> {@code \"'this'\"}<\/td> <\/tr> <tr> <td> {@code SQUOTE : '\\'';}<\/td> <td> {@code '\\''}<\/td> <td> {@code \"'\\\\''\"}<\/td> <\/tr> <tr> <td> {@code ID : [A-Z]+;}<\/td> <td>n\/a<\/td> <td> {@code null}<\/td> <\/tr> <\/table>\n * @param tokenType The token type.\n * @return The string literal associated with the specified token type, or{@code null} if no string literal is associated with the type.\n *\/\n","getSymbolicName":"\/** \n * Gets the symbolic name associated with a token type. The string returned by this method, when not  {@code null}, can be used unaltered in a parser grammar to represent this token type. <p>This method supports token types defined by any of the following methods:<\/p> <ul> <li>Tokens created by lexer rules.<\/li> <li>Tokens defined in a <code>tokens{}<\/code> block in a lexer or parser grammar.<\/li> <li>The implicitly defined  {@code EOF} token, which has the token type{@link Token#EOF}.<\/li> <\/ul> <p>The following table shows examples of lexer rules and the literal names assigned to the corresponding token types.<\/p> <table> <tr> <th>Rule<\/th> <th>Symbolic Name<\/th> <\/tr> <tr> <td> {@code THIS : 'this';}<\/td> <td> {@code THIS}<\/td> <\/tr> <tr> <td> {@code SQUOTE : '\\'';}<\/td> <td> {@code SQUOTE}<\/td> <\/tr> <tr> <td> {@code ID : [A-Z]+;}<\/td> <td> {@code ID}<\/td> <\/tr> <\/table>\n * @param tokenType The token type.\n * @return The symbolic name associated with the specified token type, or{@code null} if no symbolic name is associated with the type.\n *\/\n","getMaxTokenType":"\/** \n * Returns the highest token type value. It can be used to iterate from zero to that number, inclusively, thus querying all stored entries.\n * @return the highest token type value\n *\/\n"}}
{"InterpreterRuleContext":{"InterpreterRuleContext":"\/** \n * Constructs a new  {@link InterpreterRuleContext} with the specifiedparent, invoking state, and rule index.\n * @param parent The parent context.\n * @param invokingStateNumber The invoking state number.\n * @param ruleIndex The rule index for the current context.\n *\/\n"}}
{"RecognitionException":{"getExpectedTokens":"\/** \n * Gets the set of input symbols which could potentially follow the previously matched symbol at the time this exception was thrown. <p>If the set of expected tokens is not known and could not be computed, this method returns  {@code null}.<\/p>\n * @return The set of token types that could potentially follow the currentstate in the ATN, or  {@code null} if the information is not available.\n *\/\n","getRecognizer":"\/** \n * Gets the  {@link Recognizer} where this exception occurred.<p>If the recognizer is not available, this method returns  {@code null}.<\/p>\n * @return The recognizer where this exception occurred, or {@code null} ifthe recognizer is not available.\n *\/\n","getOffendingState":"\/** \n * Get the ATN state number the parser was in at the time the error occurred. For  {@link NoViableAltException} and{@link LexerNoViableAltException} exceptions, this is the{@link DecisionState} number. For others, it is the state whose outgoingedge we couldn't match. <p>If the state number is not known, this method returns -1.<\/p>\n *\/\n","getCtx":"\/** \n * Gets the  {@link RuleContext} at the time this exception was thrown.<p>If the context is not available, this method returns  {@code null}.<\/p>\n * @return The {@link RuleContext} at the time this exception was thrown.If the context is not available, this method returns  {@code null}.\n *\/\n","getInputStream":"\/** \n * Gets the input stream which is the symbol source for the recognizer where this exception was thrown. <p>If the input stream is not available, this method returns  {@code null}.<\/p>\n * @return The input stream which is the symbol source for the recognizerwhere this exception was thrown, or  {@code null} if the stream is notavailable.\n *\/\n"}}
{"BaseErrorListener":{}}
{"ParserRuleContext":{"addErrorNode":"\/** \n * Add a child to this node based upon badToken.  It creates a ErrorNodeImpl rather than using {@link Parser#createErrorNode(ParserRuleContext,Token)}. I'm leaving this in for compatibility but the parser doesn't use this anymore.\n *\/\n","getStart":"\/** \n * Get the initial token in this context. Note that the range from start to stop is inclusive, so for rules that do not consume anything (for example, zero length or error productions) this token may exceed stop.\n *\/\n","addAnyChild":"\/** \n * Add a parse tree node to this as a child.  Works for internal and leaf nodes. Does not set parent link; other add methods must do that. Other addChild methods call this. We cannot set the parent pointer of the incoming node because the existing interfaces do not have a setParent() method and I don't want to break backward compatibility for this.\n * @since 4.7\n *\/\n","addChild":"\/** \n * Add a child to this node based upon matchedToken. It creates a TerminalNodeImpl rather than using {@link Parser#createTerminalNode(ParserRuleContext,Token)}. I'm leaving this in for compatibility but the parser doesn't use this anymore.\n *\/\n","getStop":"\/** \n * Get the final token in this context. Note that the range from start to stop is inclusive, so for rules that do not consume anything (for example, zero length or error productions) this token may precede start.\n *\/\n","toInfoString":"\/** \n * Used for rule context info debugging during parse-time, not so much for ATN debugging \n *\/\n","copyFrom":"\/** \n * COPY a ctx (I'm deliberately not using copy constructor) to avoid confusion with creating node with parent. Does not copy children (except error leaves). This is used in the generated parser code to flip a generic XContext node for rule X to a YContext for alt label Y. In that sense, it is not really a generic copy function. If we do an error sync() at start of a rule, we might add error nodes to the generic XContext so this function must copy those nodes to the YContext as well else they are lost!\n *\/\n","removeLastChild":"\/** \n * Used by enterOuterAlt to toss out a RuleContext previously added as we entered a rule. If we have # label, we will need to remove generic ruleContext object.\n *\/\n"}}
{"CommonToken":{"CommonToken":"\/** \n * Constructs a new  {@link CommonToken} as a copy of another {@link Token}. <p> If  {@code oldToken} is also a {@link CommonToken} instance, the newlyconstructed token will share a reference to the  {@link #text} field andthe  {@link Pair} stored in {@link #source}. Otherwise,  {@link #text} willbe assigned the result of calling  {@link #getText}, and  {@link #source}will be constructed from the result of  {@link Token#getTokenSource} and{@link Token#getInputStream}.<\/p>\n * @param oldToken The token to copy.\n *\/\n","setText":"\/** \n * Explicitly set the text for this token. If {code text} is not {@code null}, then  {@link #getText} will return this value rather thanextracting the text from the input.\n * @param text The explicit text of the token, or {@code null} if the textshould be obtained from the input along with the start and stop indexes of the token.\n *\/\n"}}
{"BailErrorStrategy":{"recover":"\/** \n * Instead of recovering from exception  {@code e}, re-throw it wrapped in a  {@link ParseCancellationException} so it is not caught by therule function catches.  Use  {@link Exception#getCause()} to get theoriginal  {@link RecognitionException}.\n *\/\n","sync":"\/** \n * Make sure we don't attempt to recover from problems in subrules. \n *\/\n","recoverInline":"\/** \n * Make sure we don't attempt to recover inline; if the parser successfully recovers, it won't throw an exception.\n *\/\n"}}
